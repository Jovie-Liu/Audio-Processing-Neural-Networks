{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "### Random initialization; white noise data; to see if it converges to orthogonal basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operate on GPU\n",
    "dev = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data (white noise)\n",
    "N = 512\n",
    "n_sample = 100;\n",
    "batch_size = 100;\n",
    "x = torch.rand(N,n_sample, device = dev)*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5454], device='cuda:0', requires_grad=True) tensor([0.0388], device='cuda:0', requires_grad=True) tensor([0.7586], device='cuda:0', requires_grad=True) tensor([0.0649], device='cuda:0', requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.rand(1, requires_grad = True, device = dev)\n",
    "a2 = torch.rand(1, requires_grad = True, device = dev)\n",
    "a3 = torch.rand(1, requires_grad = True, device = dev)\n",
    "a4 = torch.rand(1, requires_grad = True, device = dev)\n",
    "print(a1,a2,a3,a4)\n",
    "print(a1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5580, 1.1050, 2.0936, 2.1583, 1.2282, 2.9905, 0.5601, 2.5849, 1.3103,\n",
      "        1.7071, 0.9474, 0.4678, 2.0186, 2.3792, 2.6779, 1.5153, 1.4215, 1.5121,\n",
      "        0.1231, 2.4616, 0.1045, 0.0853, 2.2903, 2.5784, 0.0123, 2.6781, 1.1079,\n",
      "        1.2148, 1.4405, 1.6577, 1.9348, 2.1631, 1.8764, 0.9698, 0.2792, 2.2116,\n",
      "        2.2410, 2.8711, 1.1760, 2.9956, 0.1928, 0.4002, 2.0546, 1.2711, 2.3422,\n",
      "        3.1148, 1.1629, 2.0339, 1.6107, 1.1515, 3.1112, 1.0367, 0.9851, 2.4173,\n",
      "        0.6416, 0.7772, 2.7525, 0.0611, 2.4794, 1.6451, 2.9996, 1.1254, 0.2746,\n",
      "        1.3886, 1.7065, 2.1581, 0.9915, 1.1825, 0.9547, 2.6626, 0.3753, 2.0896,\n",
      "        1.9502, 0.3263, 2.2918, 1.2987, 0.9476, 0.2290, 1.0726, 1.8689, 2.0133,\n",
      "        1.1785, 0.1544, 0.9936, 1.3871, 1.7706, 2.1571, 1.0286, 1.7858, 0.3325,\n",
      "        0.7180, 2.6164, 0.0172, 0.8346, 0.3791, 1.6737, 1.7010, 2.0426, 0.5623,\n",
      "        0.3951, 0.8667, 2.9115, 1.8327, 0.9459, 2.2860, 2.1892, 0.0990, 0.8333,\n",
      "        2.1960, 0.8727, 3.0540, 0.0751, 0.2573, 1.3811, 2.1819, 2.7363, 2.8954,\n",
      "        2.6971, 2.2420, 2.7976, 1.6428, 2.6856, 3.1358, 1.3192, 2.8291, 0.6054,\n",
      "        1.2415, 0.2914, 0.1146, 0.9532, 1.8585, 0.2574, 1.3695, 2.3900, 1.3113,\n",
      "        0.3012, 2.6802, 1.3823, 0.6209, 1.3931, 1.8572, 2.8336, 2.4538, 2.3684,\n",
      "        0.8730, 3.1394, 2.8903, 1.2510, 2.7954, 2.5818, 0.1824, 0.2531, 0.0349,\n",
      "        1.0935, 2.4314, 2.2089, 2.0827, 2.9392, 1.3530, 3.0856, 3.0243, 1.0053,\n",
      "        3.1217, 0.7323, 2.6913, 1.9841, 2.6970, 2.7047, 3.1415, 0.4319, 1.8418,\n",
      "        1.9891, 2.1104, 1.7927, 0.8771, 0.4404, 1.1552, 0.9736, 0.3231, 2.9280,\n",
      "        1.2698, 1.8429, 0.4652, 1.2288, 2.7504, 1.8595, 0.9234, 0.3506, 3.1220,\n",
      "        2.7045, 0.0302, 1.2335, 1.2449, 1.1168, 0.2194, 0.8446, 2.9386, 2.3541,\n",
      "        0.8307, 2.1897, 2.1397, 0.2873, 2.9971, 2.1463, 0.7619, 1.5147, 2.0131,\n",
      "        0.3721, 2.1588, 0.2219, 0.1784, 1.7565, 1.0891, 0.8143, 1.0658, 2.6778,\n",
      "        2.4230, 2.8826, 2.5730, 1.4803, 2.5829, 0.3469, 0.0142, 2.1863, 1.1450,\n",
      "        2.6075, 0.8994, 2.6059, 0.5471, 2.8114, 0.5769, 2.0542, 0.7498, 2.7369,\n",
      "        1.6791, 1.3660, 2.8987, 2.8678, 1.1226, 1.3500, 2.2399, 1.7923, 2.1456,\n",
      "        2.0095, 2.5884, 0.5553, 0.4712, 0.8248, 1.5248, 0.2053, 1.8366, 2.3871,\n",
      "        0.7439, 0.2175, 0.4996, 0.9048, 2.8478, 1.9086, 0.1292, 1.3413, 0.5493,\n",
      "        1.6207, 2.5240, 1.9466, 1.1078, 2.7080, 0.9122, 2.2197, 2.1567, 1.6794,\n",
      "        2.4843, 2.5827, 2.7786, 1.0884, 2.1155, 0.7934, 0.5713, 0.3960, 2.1888,\n",
      "        0.4364, 2.9287, 2.4199, 2.9327, 0.5268, 2.7896, 0.8453, 0.4426, 2.9110,\n",
      "        2.1454, 2.4562, 3.0816, 0.0256, 0.7368, 0.0721, 2.7210, 2.5319, 1.0190,\n",
      "        1.9614, 1.8483, 1.8502, 1.8511, 2.7541, 1.1924, 0.1476, 2.7072, 1.3522,\n",
      "        1.0804, 0.5151, 1.5516, 2.8032, 1.1629, 1.6938, 2.8093, 2.2537, 2.9593,\n",
      "        2.0267, 2.4582, 1.0599, 2.7032, 1.8691, 0.8901, 0.1114, 1.5850, 0.6715,\n",
      "        0.9628, 0.3598, 0.9169, 0.4323, 1.6910, 2.3376, 2.3957, 1.0499, 0.7418,\n",
      "        0.1414, 0.4597, 1.7434, 3.0040, 2.8488, 1.2009, 2.4402, 0.2194, 2.8019,\n",
      "        0.0225, 1.4916, 0.9849, 0.4748, 2.2847, 0.1877, 1.3663, 0.9191, 2.5424,\n",
      "        2.6553, 2.8172, 0.9213, 1.9773, 2.7224, 2.3656, 2.4118, 1.9384, 0.7045,\n",
      "        0.8915, 2.9950, 0.3428, 1.8641, 1.7846, 2.1679, 1.4593, 1.3134, 0.3633,\n",
      "        0.7130, 1.0234, 1.4167, 0.6110, 2.4847, 3.0896, 1.9198, 0.3084, 0.0125,\n",
      "        1.5666, 3.1392, 2.4486, 0.0086, 0.0676, 2.1196, 1.2893, 2.5168, 0.2101,\n",
      "        1.0130, 0.6856, 1.4041, 2.2739, 0.3234, 2.2075, 2.8938, 0.6630, 0.6322,\n",
      "        2.2997, 2.3791, 1.7750, 0.5964, 1.0950, 0.7827, 2.2657, 0.2141, 0.3910,\n",
      "        0.9912, 2.5637, 0.6593, 0.3879, 0.7537, 2.6945, 1.4439, 2.4558, 0.0437,\n",
      "        2.4621, 2.7312, 0.0139, 0.0949, 1.3977, 1.2446, 1.2426, 1.5502, 1.6778,\n",
      "        0.7971, 2.1329, 1.9562, 2.3207, 1.6384, 2.1044, 1.8037, 2.9560, 0.3896,\n",
      "        0.9837, 0.7693, 1.1154, 0.9966, 2.3497, 1.0637, 0.6642, 2.3797, 1.9435,\n",
      "        2.9255, 0.9770, 2.7805, 0.2299, 1.9644, 0.1367, 2.9484, 2.0478, 1.3776,\n",
      "        0.9876, 2.6987, 2.3652, 1.5663, 1.0183, 0.9802, 0.5765, 0.0554, 3.0789,\n",
      "        2.2520, 1.5756, 2.2662, 1.7199, 1.5958, 0.4861, 0.6324, 0.4163, 2.5323,\n",
      "        0.3062, 2.6533, 1.9359, 1.4634, 1.0098, 2.6915, 0.1894, 1.9655, 1.9349,\n",
      "        0.6688, 0.1542, 3.1126, 1.2734, 0.7291, 0.1860, 3.0920, 1.2320, 2.4042,\n",
      "        0.4441, 1.2310, 0.4873, 2.3332, 1.6180, 1.0246, 0.6296, 2.2613, 2.0191,\n",
      "        1.0016, 0.9549, 2.5676, 0.3653, 2.0177, 0.7645, 0.7287, 1.7327, 2.4714,\n",
      "        2.3694, 0.7501, 0.6661, 2.1797, 0.2531, 0.3374, 0.1026, 0.6063],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.rand(M, requires_grad = True, device = dev)*torch.pi\n",
    "w2 = torch.rand(M, requires_grad = True, device = dev)*torch.pi\n",
    "w1.retain_grad()\n",
    "w2.retain_grad()\n",
    "print(w1)\n",
    "print(w2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.size()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward pass and compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5454,  0.0329,  0.0170,  ...,  0.0117, -0.0096, -0.0281],\n",
       "        [ 0.5454,  0.0174, -0.0231,  ..., -0.0385, -0.0131,  0.0267],\n",
       "        [ 0.5454, -0.0194, -0.0194,  ..., -0.0316,  0.0352, -0.0036],\n",
       "        ...,\n",
       "        [ 0.5454,  0.0366,  0.0303,  ..., -0.0195, -0.0295, -0.0362],\n",
       "        [ 0.5454,  0.0386,  0.0380,  ..., -0.0143, -0.0179, -0.0213],\n",
       "        [ 0.5454,  0.0319,  0.0136,  ...,  0.0283,  0.0081, -0.0149]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight matrix W1\n",
    "W1 = torch.zeros(M,N, device = dev)\n",
    "for m in range(M):\n",
    "    W1[m,0] = a1\n",
    "    for n in range(1,N):\n",
    "        W1[m,n] = a2 * torch.cos(w1[m]*n)\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency domain X\n",
    "X = torch.matmul(W1,x)/np.sqrt(N)\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07877216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X.to(\"cpu\").detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7586,  0.7586,  0.7586,  ...,  0.7586,  0.7586,  0.7586],\n",
       "        [ 0.0551,  0.0292, -0.0324,  ...,  0.0613,  0.0646,  0.0533],\n",
       "        [ 0.0285, -0.0387, -0.0326,  ...,  0.0507,  0.0636,  0.0228],\n",
       "        ...,\n",
       "        [ 0.0196, -0.0645, -0.0529,  ..., -0.0326, -0.0239,  0.0474],\n",
       "        [-0.0161, -0.0220,  0.0590,  ..., -0.0494, -0.0300,  0.0136],\n",
       "        [-0.0470,  0.0447, -0.0060,  ..., -0.0605, -0.0357, -0.0250]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight matrix W2_1 with same frequency components w1\n",
    "W2_1 = torch.zeros(N,M, device = dev)\n",
    "for m in range(M):\n",
    "    W2_1[0,m] = a3\n",
    "    for n in range(1,N):\n",
    "        W2_1[n,m] = a4 * torch.cos(w1[m]*n)\n",
    "W2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7586,  0.7586,  0.7586,  ...,  0.7586,  0.7586,  0.7586],\n",
       "        [ 0.0474, -0.0443, -0.0247,  ...,  0.0396,  0.0503, -0.0637],\n",
       "        [ 0.0043, -0.0044, -0.0461,  ..., -0.0166,  0.0129,  0.0602],\n",
       "        ...,\n",
       "        [ 0.0619,  0.0500,  0.0519,  ...,  0.0562, -0.0648,  0.0637],\n",
       "        [ 0.0586, -0.0644,  0.0162,  ...,  0.0085, -0.0523, -0.0602],\n",
       "        [ 0.0238,  0.0379, -0.0643,  ..., -0.0458, -0.0161,  0.0544]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight matrix W2_2 with different frequency components w2\n",
    "W2_2 = torch.zeros(N,M, device = dev)\n",
    "for m in range(M):\n",
    "    W2_2[0,m] = a3\n",
    "    for n in range(1,N):\n",
    "        W2_2[n,m] = a4 * torch.cos(w2[m]*n)\n",
    "W2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40914237"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.matmul(W2_1,X)/np.sqrt(N)\n",
    "np.max(y.to(\"cpu\").detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ((x-y)**2).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0130], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w1 -= lr * w1.grad\n",
    "    w1.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-51-51ffada361be>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-51-51ffada361be>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(f'epoch{epoch+1}: a1 = {a1:.3f}, loss = {loss:.8f})\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "if epoch % 2 == 0:\n",
    "    print(f'epoch{epoch+1}: a1 = {a1:.3f}, loss = {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = tensor([0.5578, 1.1050, 2.0936, 2.1582, 1.2282, 2.9904, 0.5599, 2.5849, 1.3103,\n",
      "        1.7072, 0.9475, 0.4680, 2.0186, 2.3791, 2.6778, 1.5151, 1.4215, 1.5121,\n",
      "        0.1232, 2.4615, 0.1044, 0.0854, 2.2905, 2.5783, 0.0126, 2.6780, 1.1080,\n",
      "        1.2150, 1.4406, 1.6578, 1.9349, 2.1632, 1.8766, 0.9697, 0.2795, 2.2118,\n",
      "        2.2412, 2.8711, 1.1761, 2.9956, 0.1928, 0.4003, 2.0546, 1.2710, 2.3422,\n",
      "        3.1148, 1.1629, 2.0339, 1.6108, 1.1517, 3.1112, 1.0369, 0.9851, 2.4171,\n",
      "        0.6416, 0.7770, 2.7524, 0.0611, 2.4791, 1.6450, 2.9998, 1.1256, 0.2742,\n",
      "        1.3886, 1.7065, 2.1580, 0.9913, 1.1825, 0.9546, 2.6626, 0.3753, 2.0896,\n",
      "        1.9503, 0.3263, 2.2919, 1.2989, 0.9477, 0.2290, 1.0727, 1.8689, 2.0135,\n",
      "        1.1785, 0.1546, 0.9936, 1.3871, 1.7707, 2.1572, 1.0285, 1.7857, 0.3325,\n",
      "        0.7179, 2.6163, 0.0171, 0.8345, 0.3793, 1.6738, 1.7009, 2.0428, 0.5623,\n",
      "        0.3952, 0.8667, 2.9115, 1.8327, 0.9459, 2.2857, 2.1890, 0.0991, 0.8331,\n",
      "        2.1962, 0.8726, 3.0540, 0.0750, 0.2574, 1.3810, 2.1818, 2.7362, 2.8953,\n",
      "        2.6974, 2.2421, 2.7976, 1.6429, 2.6856, 3.1356, 1.3191, 2.8290, 0.6055,\n",
      "        1.2415, 0.2914, 0.1146, 0.9531, 1.8586, 0.2574, 1.3694, 2.3898, 1.3113,\n",
      "        0.3013, 2.6802, 1.3822, 0.6211, 1.3930, 1.8573, 2.8334, 2.4539, 2.3684,\n",
      "        0.8729, 3.1402, 2.8901, 1.2511, 2.7953, 2.5818, 0.1822, 0.2531, 0.0349,\n",
      "        1.0937, 2.4311, 2.2090, 2.0827, 2.9393, 1.3527, 3.0856, 3.0244, 1.0051,\n",
      "        3.1217, 0.7324, 2.6911, 1.9838, 2.6972, 2.7047, 3.1415, 0.4319, 1.8419,\n",
      "        1.9893, 2.1106, 1.7927, 0.8772, 0.4404, 1.1548, 0.9738, 0.3234, 2.9280,\n",
      "        1.2696, 1.8430, 0.4650, 1.2289, 2.7503, 1.8595, 0.9233, 0.3504, 3.1220,\n",
      "        2.7045, 0.0302, 1.2335, 1.2447, 1.1168, 0.2193, 0.8445, 2.9386, 2.3541,\n",
      "        0.8307, 2.1896, 2.1396, 0.2873, 2.9973, 2.1465, 0.7618, 1.5145, 2.0132,\n",
      "        0.3721, 2.1586, 0.2220, 0.1784, 1.7565, 1.0892, 0.8143, 1.0659, 2.6777,\n",
      "        2.4231, 2.8826, 2.5730, 1.4803, 2.5829, 0.3468, 0.0143, 2.1863, 1.1449,\n",
      "        2.6075, 0.8995, 2.6059, 0.5471, 2.8114, 0.5768, 2.0543, 0.7496, 2.7369,\n",
      "        1.6789, 1.3660, 2.8990, 2.8679, 1.1227, 1.3500, 2.2401, 1.7923, 2.1458,\n",
      "        2.0096, 2.5884, 0.5553, 0.4713, 0.8247, 1.5247, 0.2052, 1.8364, 2.3870,\n",
      "        0.7440, 0.2175, 0.4995, 0.9049, 2.8477, 1.9086, 0.1292, 1.3412, 0.5493,\n",
      "        1.6208, 2.5238, 1.9467, 1.1079, 2.7079, 0.9121, 2.2197, 2.1569, 1.6792,\n",
      "        2.4846, 2.5827, 2.7785, 1.0884, 2.1153, 0.7935, 0.5714, 0.3961, 2.1887,\n",
      "        0.4365, 2.9287, 2.4200, 2.9328, 0.5265, 2.7894, 0.8453, 0.4428, 2.9110,\n",
      "        2.1456, 2.4563, 3.0814, 0.0257, 0.7369, 0.0724, 2.7211, 2.5318, 1.0192,\n",
      "        1.9615, 1.8481, 1.8501, 1.8511, 2.7540, 1.1924, 0.1476, 2.7071, 1.3519,\n",
      "        1.0804, 0.5152, 1.5516, 2.8032, 1.1629, 1.6937, 2.8093, 2.2537, 2.9594,\n",
      "        2.0267, 2.4582, 1.0598, 2.7033, 1.8692, 0.8900, 0.1114, 1.5850, 0.6716,\n",
      "        0.9629, 0.3601, 0.9169, 0.4323, 1.6909, 2.3376, 2.3959, 1.0499, 0.7416,\n",
      "        0.1414, 0.4598, 1.7434, 3.0039, 2.8488, 1.2010, 2.4406, 0.2193, 2.8018,\n",
      "        0.0225, 1.4917, 0.9849, 0.4745, 2.2845, 0.1877, 1.3662, 0.9190, 2.5423,\n",
      "        2.6555, 2.8171, 0.9213, 1.9773, 2.7224, 2.3655, 2.4120, 1.9382, 0.7046,\n",
      "        0.8914, 2.9949, 0.3430, 1.8640, 1.7844, 2.1679, 1.4593, 1.3135, 0.3635,\n",
      "        0.7131, 1.0233, 1.4166, 0.6110, 2.4849, 3.0895, 1.9195, 0.3084, 0.0127,\n",
      "        1.5667, 3.1400, 2.4487, 0.0087, 0.0675, 2.1196, 1.2892, 2.5168, 0.2100,\n",
      "        1.0129, 0.6857, 1.4041, 2.2739, 0.3237, 2.2075, 2.8936, 0.6630, 0.6321,\n",
      "        2.2997, 2.3790, 1.7750, 0.5962, 1.0950, 0.7826, 2.2657, 0.2142, 0.3911,\n",
      "        0.9910, 2.5634, 0.6593, 0.3877, 0.7536, 2.6945, 1.4439, 2.4559, 0.0437,\n",
      "        2.4620, 2.7313, 0.0139, 0.0950, 1.3977, 1.2444, 1.2426, 1.5502, 1.6775,\n",
      "        0.7972, 2.1330, 1.9561, 2.3210, 1.6382, 2.1044, 1.8037, 2.9560, 0.3895,\n",
      "        0.9837, 0.7693, 1.1151, 0.9967, 2.3497, 1.0638, 0.6642, 2.3795, 1.9436,\n",
      "        2.9256, 0.9770, 2.7805, 0.2299, 1.9644, 0.1366, 2.9483, 2.0475, 1.3778,\n",
      "        0.9876, 2.6990, 2.3650, 1.5663, 1.0185, 0.9802, 0.5764, 0.0554, 3.0787,\n",
      "        2.2520, 1.5755, 2.2661, 1.7196, 1.5958, 0.4861, 0.6323, 0.4164, 2.5322,\n",
      "        0.3063, 2.6533, 1.9358, 1.4635, 1.0098, 2.6913, 0.1895, 1.9654, 1.9349,\n",
      "        0.6689, 0.1545, 3.1126, 1.2735, 0.7291, 0.1860, 3.0919, 1.2319, 2.4043,\n",
      "        0.4442, 1.2309, 0.4872, 2.3331, 1.6179, 1.0245, 0.6297, 2.2614, 2.0191,\n",
      "        1.0017, 0.9547, 2.5678, 0.3652, 2.0176, 0.7644, 0.7286, 1.7325, 2.4715,\n",
      "        2.3695, 0.7499, 0.6660, 2.1797, 0.2530, 0.3373, 0.1026, 0.6064],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>), loss = 0.33311817049980164\n"
     ]
    }
   ],
   "source": [
    "print(f'w1 = {w1}, loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0217], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randperm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
