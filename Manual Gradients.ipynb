{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(M,dev):\n",
    "    a1 = torch.rand(1) + 0.5\n",
    "    a2 = torch.rand(1) + 0.5\n",
    "    a3 = torch.rand(1) + 0.5\n",
    "    a4 = torch.rand(1) + 0.5\n",
    "    \n",
    "    w1, index = torch.sort(torch.rand(M)*torch.pi)\n",
    "    w2, index = torch.sort(torch.rand(M)*torch.pi)\n",
    "    \n",
    "    a1 = a1.to(dev)\n",
    "    a1.requires_grad_(True)\n",
    "    \n",
    "    a2 = a2.to(dev)\n",
    "    a2.requires_grad_(True)\n",
    "    \n",
    "    a3 = a3.to(dev)\n",
    "    a3.requires_grad_(True)\n",
    "    \n",
    "    a4 = a4.to(dev)\n",
    "    a4.requires_grad_(True)\n",
    "    \n",
    "    w1 = w1.to(dev)\n",
    "    w1.requires_grad_(True)\n",
    "    \n",
    "    w2 = w2.to(dev)\n",
    "    w2.requires_grad_(True)\n",
    "    \n",
    "    \n",
    "    return a1,a2,a3,a4,w1,w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_init(M,dev):\n",
    "    a1 = torch.tensor(1.0, requires_grad = True, device = dev)\n",
    "    a2 = torch.tensor(np.sqrt(2), requires_grad = True, device = dev) # sqrt(2)\n",
    "    a3 = torch.tensor(1.0, requires_grad = True, device = dev)\n",
    "    a4 = torch.tensor(np.sqrt(2), requires_grad = True, device = dev)\n",
    "\n",
    "    \n",
    "    w1 = (torch.arange(M, device = dev)*2+1)/(2*M)*torch.pi\n",
    "    w2 = (torch.arange(M, device = dev)*2+1)/(2*M)*torch.pi\n",
    "    w1.requires_grad_(True)\n",
    "    w2.requires_grad_(True)\n",
    "    # w1.retain_grad()\n",
    "    # w2.retain_grad()\n",
    "    \n",
    "    return a1,a2,a3,a4,w1,w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_id(x,a1,a2,a3,a4,w1,dev):\n",
    "    N = x.size()[0]\n",
    "    M = w1.size()[0]\n",
    "    \n",
    "    # weight matrix W1\n",
    "    W1 = a2 * torch.cos(torch.outer(w1,torch.arange(N, device = dev)))\n",
    "    W1[:,0] = a1\n",
    "    \n",
    "    # frequency domain X\n",
    "    X = torch.matmul(W1,x)/np.sqrt(N)\n",
    "    \n",
    "    # weight matrix W2_1 with same frequency components w1\n",
    "    W2_1 = a4 * torch.cos(torch.outer(torch.arange(N, device = dev),w1))\n",
    "    W2_1[0] = a3\n",
    "            \n",
    "    y = torch.matmul(W2_1,X)/np.sqrt(M)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_dif(x,a1,a2,a3,a4,w1,w2,dev):\n",
    "    N = x.size()[0]\n",
    "    M = w1.size()[0]\n",
    "    \n",
    "    # weight matrix W1\n",
    "    W1 = a2 * torch.cos(torch.outer(w1,torch.arange(N, device = dev)))\n",
    "    W1[:,0] = a1\n",
    "    \n",
    "    # frequency domain X\n",
    "    X = torch.matmul(W1,x)/np.sqrt(N)\n",
    "    \n",
    "    # weight matrix W2_2 with different frequency components w2\n",
    "    W2_2 = a4 * torch.cos(torch.outer(torch.arange(N, device = dev),w2))\n",
    "    W2_2[0] = a3\n",
    "            \n",
    "    y = torch.matmul(W2_2,X)/np.sqrt(M)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y):\n",
    "    return ((x-y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "M = 1000\n",
    "dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = tensor([1.3394], requires_grad=True), a2 = tensor([0.7492], requires_grad=True), a3 = tensor([0.9715], requires_grad=True), a4 = tensor([1.3431], requires_grad=True), w1 = tensor([0.0040, 0.0050, 0.0060, 0.0154, 0.0179, 0.0193, 0.0238, 0.0268, 0.0285,\n",
      "        0.0304, 0.0325, 0.0375, 0.0448, 0.0487, 0.0586, 0.0635, 0.0638, 0.0702,\n",
      "        0.0783, 0.0815, 0.0847, 0.0852, 0.0999, 0.1062, 0.1084, 0.1103, 0.1111,\n",
      "        0.1138, 0.1139, 0.1226, 0.1242, 0.1336, 0.1366, 0.1391, 0.1406, 0.1473,\n",
      "        0.1482, 0.1490, 0.1511, 0.1521, 0.1543, 0.1555, 0.1620, 0.1644, 0.1647,\n",
      "        0.1682, 0.1691, 0.1724, 0.1726, 0.1753, 0.1776, 0.1781, 0.1785, 0.1903,\n",
      "        0.1911, 0.1978, 0.1984, 0.2004, 0.2035, 0.2064, 0.2074, 0.2093, 0.2097,\n",
      "        0.2100, 0.2125, 0.2142, 0.2234, 0.2246, 0.2248, 0.2253, 0.2375, 0.2411,\n",
      "        0.2423, 0.2429, 0.2468, 0.2490, 0.2527, 0.2539, 0.2611, 0.2720, 0.2729,\n",
      "        0.2878, 0.2913, 0.2937, 0.2946, 0.2975, 0.3024, 0.3078, 0.3091, 0.3120,\n",
      "        0.3131, 0.3139, 0.3141, 0.3173, 0.3182, 0.3183, 0.3187, 0.3216, 0.3235,\n",
      "        0.3249, 0.3276, 0.3358, 0.3401, 0.3411, 0.3449, 0.3461, 0.3462, 0.3575,\n",
      "        0.3603, 0.3681, 0.3707, 0.3722, 0.3738, 0.3755, 0.3781, 0.3848, 0.3855,\n",
      "        0.3911, 0.3911, 0.3922, 0.3927, 0.3931, 0.3974, 0.3980, 0.4063, 0.4121,\n",
      "        0.4185, 0.4223, 0.4230, 0.4239, 0.4243, 0.4247, 0.4282, 0.4298, 0.4315,\n",
      "        0.4324, 0.4343, 0.4422, 0.4467, 0.4505, 0.4519, 0.4523, 0.4526, 0.4532,\n",
      "        0.4541, 0.4570, 0.4573, 0.4620, 0.4681, 0.4725, 0.4760, 0.4810, 0.4816,\n",
      "        0.4835, 0.4884, 0.4901, 0.4922, 0.5057, 0.5085, 0.5098, 0.5113, 0.5114,\n",
      "        0.5122, 0.5132, 0.5140, 0.5159, 0.5164, 0.5176, 0.5199, 0.5201, 0.5202,\n",
      "        0.5264, 0.5274, 0.5330, 0.5343, 0.5355, 0.5362, 0.5431, 0.5443, 0.5536,\n",
      "        0.5615, 0.5624, 0.5698, 0.5739, 0.5779, 0.5797, 0.5849, 0.5861, 0.5864,\n",
      "        0.5878, 0.5884, 0.5897, 0.5921, 0.5929, 0.5958, 0.6003, 0.6023, 0.6037,\n",
      "        0.6249, 0.6304, 0.6317, 0.6420, 0.6455, 0.6503, 0.6544, 0.6588, 0.6633,\n",
      "        0.6673, 0.6674, 0.6687, 0.6698, 0.6724, 0.6732, 0.6776, 0.6788, 0.6792,\n",
      "        0.6855, 0.6863, 0.6965, 0.7088, 0.7125, 0.7134, 0.7170, 0.7177, 0.7205,\n",
      "        0.7226, 0.7329, 0.7335, 0.7340, 0.7353, 0.7381, 0.7381, 0.7438, 0.7483,\n",
      "        0.7525, 0.7643, 0.7648, 0.7671, 0.7713, 0.7715, 0.7716, 0.7717, 0.7717,\n",
      "        0.7724, 0.7735, 0.7740, 0.7759, 0.7777, 0.7821, 0.7821, 0.7855, 0.7859,\n",
      "        0.7934, 0.7934, 0.8004, 0.8014, 0.8024, 0.8029, 0.8068, 0.8070, 0.8074,\n",
      "        0.8120, 0.8167, 0.8171, 0.8195, 0.8228, 0.8229, 0.8314, 0.8399, 0.8430,\n",
      "        0.8459, 0.8470, 0.8609, 0.8661, 0.8701, 0.8741, 0.8776, 0.8779, 0.8792,\n",
      "        0.8798, 0.8814, 0.8824, 0.8847, 0.8856, 0.8878, 0.8898, 0.8937, 0.8985,\n",
      "        0.9001, 0.9007, 0.9020, 0.9067, 0.9091, 0.9158, 0.9160, 0.9193, 0.9197,\n",
      "        0.9198, 0.9206, 0.9282, 0.9297, 0.9315, 0.9366, 0.9454, 0.9473, 0.9483,\n",
      "        0.9497, 0.9509, 0.9515, 0.9563, 0.9569, 0.9582, 0.9589, 0.9655, 0.9657,\n",
      "        0.9667, 0.9711, 0.9789, 0.9809, 0.9860, 0.9938, 1.0027, 1.0089, 1.0131,\n",
      "        1.0138, 1.0147, 1.0179, 1.0186, 1.0204, 1.0204, 1.0228, 1.0288, 1.0313,\n",
      "        1.0332, 1.0412, 1.0430, 1.0525, 1.0541, 1.0567, 1.0607, 1.0617, 1.0624,\n",
      "        1.0632, 1.0709, 1.0710, 1.0823, 1.0850, 1.0875, 1.0904, 1.0911, 1.0927,\n",
      "        1.0948, 1.0953, 1.0981, 1.0984, 1.0984, 1.1025, 1.1030, 1.1034, 1.1049,\n",
      "        1.1075, 1.1109, 1.1113, 1.1142, 1.1162, 1.1171, 1.1171, 1.1255, 1.1306,\n",
      "        1.1385, 1.1393, 1.1409, 1.1451, 1.1485, 1.1529, 1.1609, 1.1625, 1.1634,\n",
      "        1.1695, 1.1698, 1.1754, 1.1801, 1.1842, 1.1959, 1.1978, 1.2000, 1.2052,\n",
      "        1.2081, 1.2144, 1.2166, 1.2179, 1.2212, 1.2217, 1.2279, 1.2294, 1.2361,\n",
      "        1.2434, 1.2476, 1.2485, 1.2604, 1.2635, 1.2643, 1.2643, 1.2648, 1.2691,\n",
      "        1.2739, 1.2750, 1.2765, 1.2772, 1.2823, 1.2881, 1.2926, 1.3007, 1.3021,\n",
      "        1.3022, 1.3036, 1.3080, 1.3086, 1.3111, 1.3141, 1.3218, 1.3228, 1.3237,\n",
      "        1.3240, 1.3266, 1.3275, 1.3279, 1.3304, 1.3325, 1.3326, 1.3360, 1.3371,\n",
      "        1.3372, 1.3386, 1.3398, 1.3415, 1.3434, 1.3437, 1.3466, 1.3482, 1.3554,\n",
      "        1.3566, 1.3613, 1.3629, 1.3699, 1.3710, 1.3797, 1.3992, 1.4019, 1.4019,\n",
      "        1.4060, 1.4090, 1.4090, 1.4116, 1.4128, 1.4169, 1.4193, 1.4288, 1.4336,\n",
      "        1.4381, 1.4417, 1.4491, 1.4514, 1.4587, 1.4596, 1.4616, 1.4667, 1.4676,\n",
      "        1.4680, 1.4697, 1.4796, 1.4864, 1.4950, 1.4985, 1.4991, 1.4998, 1.5011,\n",
      "        1.5047, 1.5083, 1.5098, 1.5123, 1.5139, 1.5238, 1.5307, 1.5328, 1.5363,\n",
      "        1.5370, 1.5378, 1.5379, 1.5381, 1.5397, 1.5424, 1.5451, 1.5466, 1.5473,\n",
      "        1.5502, 1.5527, 1.5558, 1.5643, 1.5723, 1.5776, 1.5815, 1.5837, 1.5850,\n",
      "        1.5905, 1.5943, 1.5956, 1.5971, 1.5986, 1.6019, 1.6068, 1.6085, 1.6095,\n",
      "        1.6111, 1.6117, 1.6160, 1.6236, 1.6260, 1.6298, 1.6370, 1.6376, 1.6414,\n",
      "        1.6447, 1.6490, 1.6522, 1.6557, 1.6586, 1.6611, 1.6646, 1.6653, 1.6791,\n",
      "        1.6799, 1.6850, 1.6858, 1.6858, 1.6862, 1.6899, 1.6941, 1.6962, 1.7005,\n",
      "        1.7082, 1.7096, 1.7176, 1.7179, 1.7206, 1.7226, 1.7283, 1.7311, 1.7311,\n",
      "        1.7362, 1.7388, 1.7428, 1.7469, 1.7477, 1.7589, 1.7590, 1.7711, 1.7761,\n",
      "        1.7799, 1.7840, 1.7857, 1.7870, 1.7913, 1.7939, 1.7978, 1.8023, 1.8040,\n",
      "        1.8085, 1.8132, 1.8150, 1.8175, 1.8205, 1.8241, 1.8280, 1.8312, 1.8361,\n",
      "        1.8369, 1.8389, 1.8404, 1.8422, 1.8444, 1.8483, 1.8487, 1.8519, 1.8551,\n",
      "        1.8562, 1.8609, 1.8730, 1.8808, 1.8891, 1.8901, 1.8909, 1.8948, 1.8968,\n",
      "        1.9004, 1.9036, 1.9042, 1.9096, 1.9122, 1.9163, 1.9196, 1.9206, 1.9251,\n",
      "        1.9275, 1.9326, 1.9346, 1.9354, 1.9356, 1.9372, 1.9400, 1.9410, 1.9421,\n",
      "        1.9436, 1.9465, 1.9516, 1.9530, 1.9547, 1.9548, 1.9590, 1.9642, 1.9733,\n",
      "        1.9800, 1.9840, 1.9854, 1.9871, 1.9900, 1.9914, 1.9926, 1.9951, 1.9954,\n",
      "        1.9966, 2.0038, 2.0054, 2.0060, 2.0127, 2.0155, 2.0259, 2.0329, 2.0377,\n",
      "        2.0387, 2.0438, 2.0459, 2.0490, 2.0509, 2.0518, 2.0530, 2.0601, 2.0611,\n",
      "        2.0662, 2.0747, 2.0761, 2.0779, 2.0905, 2.0931, 2.1010, 2.1051, 2.1083,\n",
      "        2.1160, 2.1188, 2.1212, 2.1220, 2.1242, 2.1247, 2.1286, 2.1301, 2.1313,\n",
      "        2.1322, 2.1338, 2.1356, 2.1417, 2.1438, 2.1438, 2.1439, 2.1449, 2.1449,\n",
      "        2.1467, 2.1478, 2.1508, 2.1560, 2.1577, 2.1583, 2.1589, 2.1642, 2.1702,\n",
      "        2.1714, 2.1765, 2.1782, 2.1802, 2.1884, 2.1909, 2.1970, 2.2032, 2.2076,\n",
      "        2.2148, 2.2203, 2.2217, 2.2256, 2.2316, 2.2348, 2.2353, 2.2409, 2.2424,\n",
      "        2.2434, 2.2450, 2.2484, 2.2491, 2.2504, 2.2526, 2.2527, 2.2530, 2.2537,\n",
      "        2.2554, 2.2566, 2.2616, 2.2651, 2.2656, 2.2662, 2.2734, 2.2800, 2.2845,\n",
      "        2.2917, 2.2939, 2.2974, 2.2980, 2.3065, 2.3069, 2.3083, 2.3113, 2.3147,\n",
      "        2.3197, 2.3199, 2.3200, 2.3283, 2.3392, 2.3401, 2.3437, 2.3470, 2.3478,\n",
      "        2.3499, 2.3535, 2.3557, 2.3568, 2.3572, 2.3598, 2.3600, 2.3613, 2.3625,\n",
      "        2.3628, 2.3645, 2.3674, 2.3696, 2.3715, 2.3728, 2.3736, 2.3838, 2.3859,\n",
      "        2.3876, 2.3881, 2.4017, 2.4032, 2.4049, 2.4107, 2.4175, 2.4181, 2.4203,\n",
      "        2.4204, 2.4231, 2.4321, 2.4324, 2.4352, 2.4428, 2.4443, 2.4466, 2.4613,\n",
      "        2.4620, 2.4620, 2.4737, 2.4841, 2.4883, 2.4903, 2.4910, 2.4974, 2.5002,\n",
      "        2.5007, 2.5108, 2.5143, 2.5170, 2.5186, 2.5217, 2.5346, 2.5385, 2.5448,\n",
      "        2.5516, 2.5532, 2.5548, 2.5552, 2.5571, 2.5575, 2.5601, 2.5603, 2.5611,\n",
      "        2.5627, 2.5675, 2.5695, 2.5710, 2.5749, 2.5786, 2.5822, 2.5947, 2.5963,\n",
      "        2.5970, 2.6042, 2.6050, 2.6055, 2.6130, 2.6141, 2.6157, 2.6225, 2.6239,\n",
      "        2.6342, 2.6354, 2.6360, 2.6394, 2.6412, 2.6423, 2.6480, 2.6539, 2.6568,\n",
      "        2.6609, 2.6615, 2.6640, 2.6694, 2.6711, 2.6734, 2.6751, 2.6752, 2.6781,\n",
      "        2.6805, 2.6824, 2.6849, 2.6869, 2.6875, 2.6882, 2.6887, 2.6909, 2.6992,\n",
      "        2.7016, 2.7023, 2.7068, 2.7070, 2.7086, 2.7094, 2.7101, 2.7124, 2.7135,\n",
      "        2.7166, 2.7188, 2.7294, 2.7330, 2.7337, 2.7356, 2.7387, 2.7409, 2.7415,\n",
      "        2.7444, 2.7480, 2.7495, 2.7568, 2.7661, 2.7686, 2.7715, 2.7735, 2.7745,\n",
      "        2.7776, 2.7798, 2.7802, 2.7838, 2.7863, 2.7865, 2.7891, 2.7995, 2.8090,\n",
      "        2.8121, 2.8179, 2.8220, 2.8224, 2.8238, 2.8271, 2.8288, 2.8300, 2.8306,\n",
      "        2.8337, 2.8341, 2.8362, 2.8364, 2.8437, 2.8477, 2.8479, 2.8481, 2.8509,\n",
      "        2.8538, 2.8575, 2.8578, 2.8620, 2.8634, 2.8641, 2.8652, 2.8655, 2.8726,\n",
      "        2.8742, 2.8785, 2.8904, 2.8942, 2.8963, 2.8972, 2.9009, 2.9013, 2.9042,\n",
      "        2.9044, 2.9047, 2.9074, 2.9081, 2.9098, 2.9103, 2.9141, 2.9149, 2.9159,\n",
      "        2.9291, 2.9292, 2.9325, 2.9459, 2.9460, 2.9496, 2.9496, 2.9506, 2.9526,\n",
      "        2.9555, 2.9560, 2.9608, 2.9611, 2.9660, 2.9665, 2.9749, 2.9797, 2.9808,\n",
      "        2.9836, 2.9844, 2.9872, 2.9961, 2.9998, 3.0057, 3.0063, 3.0064, 3.0238,\n",
      "        3.0263, 3.0290, 3.0308, 3.0323, 3.0325, 3.0326, 3.0354, 3.0404, 3.0457,\n",
      "        3.0462, 3.0497, 3.0559, 3.0574, 3.0596, 3.0621, 3.0658, 3.0751, 3.0753,\n",
      "        3.0800, 3.0804, 3.0903, 3.0907, 3.0927, 3.0928, 3.0953, 3.0995, 3.1007,\n",
      "        3.1041, 3.1050, 3.1052, 3.1054, 3.1075, 3.1099, 3.1103, 3.1118, 3.1124,\n",
      "        3.1149, 3.1196, 3.1201, 3.1205, 3.1217, 3.1234, 3.1235, 3.1290, 3.1298,\n",
      "        3.1361], requires_grad=True), w2 = tensor([0.0104, 0.0196, 0.0223, 0.0231, 0.0255, 0.0275, 0.0303, 0.0352, 0.0363,\n",
      "        0.0366, 0.0378, 0.0438, 0.0479, 0.0509, 0.0557, 0.0571, 0.0597, 0.0626,\n",
      "        0.0671, 0.0687, 0.0699, 0.0703, 0.0746, 0.0761, 0.0790, 0.0800, 0.0807,\n",
      "        0.0812, 0.0857, 0.0919, 0.0924, 0.0965, 0.1077, 0.1128, 0.1145, 0.1149,\n",
      "        0.1167, 0.1247, 0.1284, 0.1295, 0.1321, 0.1342, 0.1363, 0.1372, 0.1385,\n",
      "        0.1440, 0.1444, 0.1483, 0.1534, 0.1576, 0.1582, 0.1621, 0.1645, 0.1679,\n",
      "        0.1705, 0.1735, 0.1739, 0.1765, 0.1796, 0.1842, 0.1885, 0.1938, 0.1987,\n",
      "        0.2011, 0.2016, 0.2018, 0.2035, 0.2047, 0.2087, 0.2100, 0.2129, 0.2135,\n",
      "        0.2151, 0.2163, 0.2175, 0.2184, 0.2190, 0.2208, 0.2269, 0.2344, 0.2393,\n",
      "        0.2468, 0.2484, 0.2504, 0.2560, 0.2573, 0.2593, 0.2593, 0.2611, 0.2612,\n",
      "        0.2616, 0.2666, 0.2672, 0.2678, 0.2693, 0.2697, 0.2698, 0.2745, 0.2748,\n",
      "        0.2840, 0.2859, 0.2889, 0.2901, 0.2951, 0.3007, 0.3014, 0.3023, 0.3039,\n",
      "        0.3135, 0.3139, 0.3178, 0.3211, 0.3243, 0.3304, 0.3326, 0.3373, 0.3385,\n",
      "        0.3396, 0.3418, 0.3464, 0.3526, 0.3538, 0.3581, 0.3618, 0.3640, 0.3642,\n",
      "        0.3646, 0.3695, 0.3724, 0.3775, 0.3797, 0.3812, 0.3825, 0.3962, 0.4050,\n",
      "        0.4101, 0.4143, 0.4155, 0.4183, 0.4230, 0.4258, 0.4279, 0.4281, 0.4308,\n",
      "        0.4328, 0.4344, 0.4378, 0.4381, 0.4457, 0.4462, 0.4485, 0.4556, 0.4582,\n",
      "        0.4585, 0.4623, 0.4636, 0.4721, 0.4757, 0.4786, 0.4809, 0.4868, 0.4899,\n",
      "        0.4923, 0.4925, 0.4947, 0.5015, 0.5026, 0.5038, 0.5042, 0.5157, 0.5191,\n",
      "        0.5254, 0.5329, 0.5343, 0.5354, 0.5360, 0.5372, 0.5453, 0.5454, 0.5472,\n",
      "        0.5489, 0.5516, 0.5581, 0.5582, 0.5584, 0.5618, 0.5720, 0.5724, 0.5759,\n",
      "        0.5795, 0.5798, 0.5813, 0.5821, 0.5837, 0.5843, 0.5866, 0.6007, 0.6085,\n",
      "        0.6091, 0.6144, 0.6197, 0.6210, 0.6213, 0.6244, 0.6279, 0.6334, 0.6390,\n",
      "        0.6391, 0.6423, 0.6443, 0.6449, 0.6505, 0.6532, 0.6548, 0.6574, 0.6585,\n",
      "        0.6599, 0.6610, 0.6617, 0.6643, 0.6664, 0.6690, 0.6700, 0.6708, 0.6720,\n",
      "        0.6724, 0.6814, 0.6836, 0.6871, 0.6882, 0.6889, 0.6929, 0.6971, 0.6976,\n",
      "        0.7009, 0.7017, 0.7026, 0.7097, 0.7103, 0.7121, 0.7122, 0.7184, 0.7192,\n",
      "        0.7205, 0.7215, 0.7246, 0.7263, 0.7271, 0.7357, 0.7405, 0.7502, 0.7533,\n",
      "        0.7541, 0.7584, 0.7629, 0.7666, 0.7701, 0.7738, 0.7758, 0.7803, 0.7812,\n",
      "        0.7826, 0.7890, 0.7917, 0.7939, 0.7942, 0.8021, 0.8044, 0.8338, 0.8353,\n",
      "        0.8385, 0.8454, 0.8540, 0.8562, 0.8585, 0.8600, 0.8634, 0.8687, 0.8747,\n",
      "        0.8775, 0.8783, 0.8834, 0.8885, 0.8915, 0.8917, 0.8930, 0.8984, 0.9008,\n",
      "        0.9074, 0.9155, 0.9236, 0.9241, 0.9263, 0.9268, 0.9318, 0.9367, 0.9369,\n",
      "        0.9403, 0.9459, 0.9498, 0.9502, 0.9508, 0.9517, 0.9529, 0.9648, 0.9710,\n",
      "        0.9778, 0.9788, 0.9794, 0.9852, 0.9890, 0.9920, 0.9926, 0.9941, 0.9966,\n",
      "        0.9979, 0.9985, 1.0021, 1.0083, 1.0150, 1.0157, 1.0167, 1.0270, 1.0277,\n",
      "        1.0300, 1.0300, 1.0333, 1.0357, 1.0364, 1.0424, 1.0436, 1.0457, 1.0476,\n",
      "        1.0489, 1.0499, 1.0546, 1.0579, 1.0618, 1.0633, 1.0634, 1.0659, 1.0667,\n",
      "        1.0667, 1.0753, 1.0758, 1.0773, 1.0778, 1.0789, 1.0792, 1.0821, 1.0844,\n",
      "        1.0860, 1.0873, 1.0921, 1.0966, 1.0997, 1.1012, 1.1079, 1.1091, 1.1118,\n",
      "        1.1129, 1.1334, 1.1356, 1.1359, 1.1360, 1.1396, 1.1519, 1.1568, 1.1578,\n",
      "        1.1579, 1.1583, 1.1652, 1.1747, 1.1752, 1.1874, 1.1894, 1.1901, 1.1916,\n",
      "        1.1927, 1.1933, 1.1934, 1.2035, 1.2066, 1.2123, 1.2155, 1.2162, 1.2232,\n",
      "        1.2260, 1.2268, 1.2283, 1.2291, 1.2319, 1.2343, 1.2423, 1.2477, 1.2497,\n",
      "        1.2511, 1.2533, 1.2566, 1.2574, 1.2650, 1.2652, 1.2722, 1.2783, 1.2788,\n",
      "        1.2819, 1.2894, 1.2922, 1.2938, 1.2963, 1.3020, 1.3027, 1.3071, 1.3158,\n",
      "        1.3159, 1.3203, 1.3204, 1.3264, 1.3302, 1.3338, 1.3412, 1.3458, 1.3591,\n",
      "        1.3625, 1.3729, 1.3760, 1.3825, 1.3837, 1.3857, 1.3896, 1.3901, 1.3936,\n",
      "        1.3966, 1.3975, 1.3998, 1.4006, 1.4021, 1.4074, 1.4097, 1.4110, 1.4118,\n",
      "        1.4136, 1.4208, 1.4226, 1.4310, 1.4387, 1.4396, 1.4407, 1.4439, 1.4443,\n",
      "        1.4457, 1.4493, 1.4499, 1.4559, 1.4627, 1.4634, 1.4700, 1.4704, 1.4718,\n",
      "        1.4729, 1.4738, 1.4744, 1.4747, 1.4753, 1.4755, 1.4763, 1.4771, 1.4774,\n",
      "        1.4812, 1.4818, 1.4830, 1.4838, 1.4865, 1.4920, 1.5028, 1.5058, 1.5064,\n",
      "        1.5094, 1.5095, 1.5100, 1.5127, 1.5141, 1.5237, 1.5248, 1.5276, 1.5281,\n",
      "        1.5324, 1.5332, 1.5370, 1.5459, 1.5492, 1.5509, 1.5513, 1.5514, 1.5516,\n",
      "        1.5583, 1.5587, 1.5595, 1.5608, 1.5663, 1.5689, 1.5705, 1.5770, 1.5804,\n",
      "        1.5833, 1.5859, 1.5878, 1.5957, 1.5981, 1.5991, 1.6018, 1.6040, 1.6053,\n",
      "        1.6071, 1.6100, 1.6153, 1.6175, 1.6193, 1.6270, 1.6276, 1.6276, 1.6336,\n",
      "        1.6346, 1.6364, 1.6369, 1.6375, 1.6390, 1.6458, 1.6530, 1.6556, 1.6562,\n",
      "        1.6608, 1.6793, 1.6798, 1.6799, 1.6867, 1.6987, 1.6995, 1.7057, 1.7061,\n",
      "        1.7086, 1.7108, 1.7117, 1.7162, 1.7187, 1.7253, 1.7292, 1.7425, 1.7462,\n",
      "        1.7533, 1.7547, 1.7581, 1.7612, 1.7663, 1.7758, 1.7784, 1.7853, 1.7859,\n",
      "        1.7884, 1.7904, 1.7923, 1.7934, 1.7980, 1.7986, 1.7996, 1.8044, 1.8081,\n",
      "        1.8083, 1.8101, 1.8140, 1.8197, 1.8199, 1.8240, 1.8241, 1.8256, 1.8291,\n",
      "        1.8313, 1.8439, 1.8458, 1.8558, 1.8595, 1.8756, 1.8786, 1.8809, 1.8828,\n",
      "        1.8847, 1.8884, 1.9018, 1.9038, 1.9050, 1.9059, 1.9064, 1.9104, 1.9186,\n",
      "        1.9244, 1.9315, 1.9332, 1.9341, 1.9347, 1.9368, 1.9371, 1.9394, 1.9408,\n",
      "        1.9451, 1.9523, 1.9525, 1.9601, 1.9644, 1.9668, 1.9683, 1.9685, 1.9699,\n",
      "        1.9708, 1.9720, 1.9753, 1.9755, 1.9757, 1.9797, 1.9819, 1.9841, 1.9842,\n",
      "        1.9884, 1.9937, 2.0041, 2.0066, 2.0102, 2.0176, 2.0184, 2.0193, 2.0242,\n",
      "        2.0250, 2.0256, 2.0268, 2.0289, 2.0293, 2.0340, 2.0357, 2.0398, 2.0419,\n",
      "        2.0476, 2.0515, 2.0530, 2.0563, 2.0572, 2.0586, 2.0604, 2.0614, 2.0631,\n",
      "        2.0651, 2.0652, 2.0655, 2.0719, 2.0741, 2.0784, 2.0812, 2.0860, 2.0878,\n",
      "        2.0883, 2.0892, 2.0945, 2.0979, 2.1001, 2.1013, 2.1020, 2.1099, 2.1107,\n",
      "        2.1142, 2.1349, 2.1370, 2.1447, 2.1466, 2.1573, 2.1608, 2.1625, 2.1655,\n",
      "        2.1662, 2.1731, 2.1765, 2.1796, 2.1814, 2.1871, 2.1953, 2.1963, 2.1994,\n",
      "        2.2039, 2.2046, 2.2062, 2.2120, 2.2121, 2.2125, 2.2194, 2.2248, 2.2274,\n",
      "        2.2286, 2.2378, 2.2391, 2.2536, 2.2600, 2.2676, 2.2736, 2.2804, 2.2836,\n",
      "        2.2838, 2.2867, 2.2874, 2.2913, 2.2914, 2.2926, 2.2967, 2.2968, 2.2988,\n",
      "        2.2989, 2.3022, 2.3030, 2.3081, 2.3146, 2.3210, 2.3210, 2.3220, 2.3308,\n",
      "        2.3317, 2.3353, 2.3368, 2.3396, 2.3443, 2.3518, 2.3522, 2.3550, 2.3573,\n",
      "        2.3576, 2.3585, 2.3685, 2.3724, 2.3734, 2.3814, 2.3834, 2.3862, 2.3950,\n",
      "        2.3960, 2.4008, 2.4021, 2.4149, 2.4170, 2.4184, 2.4187, 2.4206, 2.4298,\n",
      "        2.4317, 2.4354, 2.4388, 2.4407, 2.4410, 2.4411, 2.4432, 2.4448, 2.4461,\n",
      "        2.4478, 2.4529, 2.4536, 2.4537, 2.4538, 2.4586, 2.4614, 2.4624, 2.4671,\n",
      "        2.4729, 2.4748, 2.4770, 2.4776, 2.4833, 2.4904, 2.4933, 2.4944, 2.4985,\n",
      "        2.5019, 2.5037, 2.5051, 2.5062, 2.5133, 2.5192, 2.5224, 2.5272, 2.5301,\n",
      "        2.5314, 2.5373, 2.5444, 2.5444, 2.5466, 2.5484, 2.5501, 2.5503, 2.5549,\n",
      "        2.5559, 2.5581, 2.5677, 2.5685, 2.5702, 2.5736, 2.5752, 2.5758, 2.5764,\n",
      "        2.5801, 2.5826, 2.5908, 2.5911, 2.5931, 2.5938, 2.5946, 2.5946, 2.5962,\n",
      "        2.5989, 2.6027, 2.6134, 2.6168, 2.6183, 2.6285, 2.6292, 2.6313, 2.6356,\n",
      "        2.6370, 2.6382, 2.6384, 2.6446, 2.6525, 2.6546, 2.6552, 2.6644, 2.6699,\n",
      "        2.6718, 2.6779, 2.6780, 2.6844, 2.6847, 2.6864, 2.6881, 2.6941, 2.6964,\n",
      "        2.7008, 2.7127, 2.7148, 2.7167, 2.7173, 2.7181, 2.7191, 2.7205, 2.7211,\n",
      "        2.7274, 2.7324, 2.7331, 2.7371, 2.7372, 2.7426, 2.7428, 2.7431, 2.7450,\n",
      "        2.7530, 2.7533, 2.7539, 2.7579, 2.7610, 2.7647, 2.7661, 2.7704, 2.7768,\n",
      "        2.7779, 2.7788, 2.7818, 2.7849, 2.7862, 2.7866, 2.7893, 2.7994, 2.8018,\n",
      "        2.8044, 2.8052, 2.8062, 2.8075, 2.8080, 2.8109, 2.8121, 2.8254, 2.8301,\n",
      "        2.8328, 2.8357, 2.8448, 2.8451, 2.8488, 2.8495, 2.8528, 2.8530, 2.8539,\n",
      "        2.8543, 2.8559, 2.8582, 2.8624, 2.8650, 2.8682, 2.8725, 2.8729, 2.8744,\n",
      "        2.8746, 2.8773, 2.8793, 2.8814, 2.8818, 2.8822, 2.8893, 2.8910, 2.8935,\n",
      "        2.8960, 2.8979, 2.9035, 2.9075, 2.9079, 2.9168, 2.9189, 2.9217, 2.9226,\n",
      "        2.9275, 2.9277, 2.9324, 2.9331, 2.9346, 2.9384, 2.9386, 2.9417, 2.9440,\n",
      "        2.9470, 2.9482, 2.9486, 2.9502, 2.9503, 2.9504, 2.9504, 2.9518, 2.9533,\n",
      "        2.9550, 2.9563, 2.9568, 2.9583, 2.9591, 2.9602, 2.9649, 2.9660, 2.9678,\n",
      "        2.9698, 2.9728, 2.9759, 2.9790, 2.9818, 2.9839, 2.9907, 2.9929, 2.9985,\n",
      "        2.9986, 3.0028, 3.0081, 3.0140, 3.0169, 3.0191, 3.0219, 3.0246, 3.0283,\n",
      "        3.0327, 3.0339, 3.0350, 3.0364, 3.0453, 3.0507, 3.0550, 3.0570, 3.0655,\n",
      "        3.0657, 3.0683, 3.0725, 3.0774, 3.0782, 3.0828, 3.0846, 3.0872, 3.0888,\n",
      "        3.0944, 3.0965, 3.1058, 3.1104, 3.1106, 3.1136, 3.1184, 3.1214, 3.1220,\n",
      "        3.1238, 3.1267, 3.1293, 3.1317, 3.1323, 3.1341, 3.1341, 3.1345, 3.1346,\n",
      "        3.1411], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a1,a2,a3,a4,w1,w2 = random_init(M,dev)\n",
    "print(f'a1 = {a1}, a2 = {a2}, a3 = {a3}, a4 = {a4}, w1 = {w1}, w2 = {w2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8321,  0.1716,  0.2912,  0.0097,  0.5804, -0.0315,  0.4208, -0.9788,\n",
       "        -0.6965,  0.1288, -0.1852,  0.0997,  0.6989,  0.6855,  0.8883,  0.3532,\n",
       "        -0.2019, -0.7404,  0.0165, -0.6417, -0.5419,  0.2563,  0.7534, -0.7029,\n",
       "        -0.4713,  0.0243, -0.8625, -0.0589,  0.6355,  0.0081,  0.0406,  0.8726,\n",
       "        -0.4646, -0.3660,  0.0552,  0.4737, -0.0621, -0.7686, -0.2630, -0.8168,\n",
       "         0.8152, -0.3126, -0.4358, -0.2170, -0.2621,  0.6809,  0.2015,  0.7723,\n",
       "        -0.2445, -0.2938, -0.2204, -0.3042, -0.2486, -0.0970, -0.5632, -0.9486,\n",
       "         0.6107, -0.1353, -0.0328,  0.7308,  0.4608, -0.7156,  0.8832,  0.7938,\n",
       "         0.4621, -0.0589,  0.0595,  0.4611, -0.7248, -0.9268, -0.8729,  0.8436,\n",
       "        -0.1111, -0.1486,  0.3076,  0.6013,  0.8056, -0.8143,  0.2173,  0.7238,\n",
       "         0.1814, -0.0570, -0.8819,  0.3411,  0.2098, -0.9269,  0.4553, -0.8590,\n",
       "         0.5324,  0.0160, -0.1348, -0.5659,  0.6818, -0.0664,  0.6412, -0.9408,\n",
       "         0.3775, -0.9061,  0.0540, -0.7646,  0.3652,  0.7249,  0.8205,  0.5326,\n",
       "         0.6199, -0.0508,  0.8716,  0.7608,  0.3616, -0.9842, -0.3124, -0.9618,\n",
       "         0.4394,  0.7337,  0.9971, -0.1526, -0.0657, -0.8727, -0.1507, -0.1491,\n",
       "         0.3169,  0.1294, -0.5681, -0.7354,  0.8550, -0.2310, -0.0228,  0.2414,\n",
       "        -0.6104,  0.8663,  0.9979, -0.9458,  0.8179,  0.6699, -0.7498,  0.4388,\n",
       "         0.7738,  0.3939,  0.2756,  0.0555,  0.1780,  0.2601, -0.4035, -0.2131,\n",
       "         0.7831, -0.8616,  0.9444, -0.3043,  0.1011,  0.1074, -0.7862, -0.6701,\n",
       "         0.9070,  0.6533,  0.4199,  0.4028,  0.6869,  0.9636,  0.1861,  0.7697,\n",
       "         0.2882, -0.0176, -0.3982, -0.5148,  0.7884,  0.4567, -0.3934, -0.8996,\n",
       "         0.3387, -0.8640, -0.5942, -0.5653,  0.7233, -0.2508,  0.6909,  0.2445,\n",
       "        -0.4758, -0.5093,  0.4141,  0.8439, -0.6655,  0.8324, -0.3602,  0.6181,\n",
       "        -0.2450,  0.2874,  0.2906, -0.8955,  0.3636,  0.3819, -0.5194, -0.7268,\n",
       "         0.2912,  0.2323, -0.3413, -0.6977,  0.3149, -0.1663,  0.8923, -0.2536,\n",
       "         0.3874, -0.5639, -0.8475, -0.5098, -0.1534,  0.3162, -0.4598,  0.5443,\n",
       "         0.0330,  0.9299, -0.7050, -0.5861,  0.7235, -0.2187, -0.5766,  0.4699,\n",
       "        -0.2612, -0.7718,  0.5254,  0.0311, -0.4780, -0.6666,  0.5517,  0.0872,\n",
       "         0.5915,  0.2927,  0.0254, -0.5680,  0.4131,  0.8373, -0.2706, -0.2407,\n",
       "         0.7690, -0.5106, -0.6609, -0.6914,  0.8802,  0.1367,  0.0424,  0.0477,\n",
       "         0.0024,  0.1273, -0.7353,  0.0582, -0.5848,  0.3118,  0.9524, -0.9848,\n",
       "         0.2697,  0.5565, -0.7377,  0.5893, -0.6361, -0.5755, -0.0106,  0.3015,\n",
       "         0.5284,  0.9036,  0.8327,  0.5402, -0.1763,  0.8164,  0.3881,  0.0077,\n",
       "        -0.3290, -0.8322, -0.2638, -0.9162, -0.6303, -0.3966, -0.1149,  0.0746,\n",
       "         0.5971,  0.0733,  0.5684, -0.6242, -0.6357,  0.9154,  0.7131,  0.4222,\n",
       "        -0.6636, -0.9118,  0.2606,  0.8219,  0.5867, -0.5952, -0.7532, -0.2912,\n",
       "        -0.2953,  0.7628,  0.9744,  0.5898,  0.4566,  0.3965, -0.5269,  0.2788,\n",
       "        -0.9623,  0.5095,  0.6311, -0.9865, -0.4591,  0.8611,  0.6567,  0.6200,\n",
       "        -0.6026,  0.8325,  0.4782, -0.7699,  0.7857, -0.3746,  0.9498, -0.5596,\n",
       "        -0.1665, -0.0776,  0.0993,  0.7176, -0.2588,  0.2142, -0.9544,  0.2321,\n",
       "        -0.8156,  0.4176, -0.1544, -0.6156,  0.9464,  0.7704,  0.7076, -0.5173,\n",
       "         0.7926,  0.1388,  0.8254,  0.3809, -0.6247,  0.3449, -0.8476,  0.7121,\n",
       "         0.4390,  0.0671, -0.7057, -0.6353, -0.3138, -0.9635,  0.7513, -0.7190,\n",
       "         0.3064, -0.7052, -0.6029, -0.7061,  0.6454,  0.9762, -0.5088, -0.0523,\n",
       "         0.8898,  0.9963,  0.4741,  0.7831,  0.7965, -0.8753, -0.1525, -0.0144,\n",
       "        -0.6659, -0.4333, -0.8304,  0.1986, -0.2077, -0.4814, -0.1786, -0.6672,\n",
       "         0.0922, -0.7944, -0.1209, -0.2381,  0.4701, -0.5437,  0.5404,  0.4436,\n",
       "         0.7783,  0.9269,  0.3732,  0.3189,  0.5298, -0.1691, -0.8524, -0.2848,\n",
       "         0.8720, -0.3446,  0.5373,  0.1026,  0.2575, -0.9945,  0.1673,  0.3343,\n",
       "         0.7465,  0.6145, -0.0183,  0.3339,  0.3190, -0.6320, -0.4024, -0.2030,\n",
       "         0.9432, -0.8360, -0.3893, -0.5368,  0.0296, -0.8760,  0.9451, -0.3797,\n",
       "        -0.9649, -0.1951, -0.5395,  0.9732, -0.5835,  0.4005, -0.6580,  0.9954,\n",
       "         0.9570,  0.1442, -0.9470,  0.9919, -0.2001, -0.7479, -0.4918, -0.7495,\n",
       "        -0.1872,  0.8412, -0.8389,  0.1325, -0.4591, -0.9735, -0.3862, -0.4697,\n",
       "         0.9534,  0.4859,  0.5633,  0.8437, -0.9437, -0.1785, -0.6695,  0.0816,\n",
       "         0.1499, -0.6661, -0.4112,  0.9539,  0.7744, -0.1789, -0.5929,  0.7331,\n",
       "        -0.3120, -0.2452,  0.5160,  0.7025, -0.0326, -0.5127, -0.4019, -0.4661,\n",
       "        -0.3029,  0.8106, -0.0024, -0.3979,  0.6929,  0.5003, -0.3452, -0.5546,\n",
       "         0.0247, -0.4354, -0.3552, -0.9816, -0.9192, -0.2640,  0.9360, -0.2333,\n",
       "         0.1489, -0.8917, -0.1763,  0.8569,  0.8719, -0.6788, -0.5949,  0.4803,\n",
       "        -0.1085,  0.1066, -0.3687, -0.1816, -0.5351, -0.8455,  0.5647,  0.1684,\n",
       "        -0.9464,  0.3369,  0.1145,  0.4899, -0.1001,  0.2395, -0.7401,  0.4182,\n",
       "        -0.8241, -0.5520,  0.8100, -0.6637, -0.3649, -0.5931,  0.8129,  0.4805,\n",
       "         0.8499, -0.9212, -0.0871, -0.7983,  0.9649,  0.6085, -0.2448, -0.5488,\n",
       "         0.4830,  0.0199,  0.9753, -0.0466, -0.7980, -0.6563,  0.3223, -0.5893,\n",
       "         0.6900,  0.7871,  0.6981,  0.8498,  0.5811,  0.2922, -0.0075, -0.5434,\n",
       "         0.6982, -0.4150,  0.2780,  0.5212, -0.0426,  0.2249, -0.8024,  0.1887,\n",
       "        -0.9918,  0.6351, -0.3388, -0.3302, -0.3347,  0.1620, -0.6468,  0.2697,\n",
       "         0.2138, -0.0698, -0.4730, -0.1085, -0.4438,  0.2744,  0.7437,  0.8453,\n",
       "        -0.2298,  0.7242, -0.7489, -0.7837, -0.0986,  0.4913,  0.9210, -0.0243,\n",
       "         0.9186, -0.2657,  0.1856, -0.0605, -0.6796, -0.0204, -0.1312, -0.8802,\n",
       "        -0.1671,  0.4154,  0.9253,  0.0729,  0.3879, -0.1042,  0.9373,  0.7583,\n",
       "        -0.9252, -0.2705, -0.8906, -0.8906,  0.4026, -0.7164,  0.1688,  0.5399,\n",
       "        -0.6993,  0.6350, -0.0179,  0.1054, -0.9424,  0.1017, -0.2313, -0.7776,\n",
       "         0.1402, -0.7429, -0.2797, -0.0280,  0.4903,  0.5536,  0.6170, -0.2585,\n",
       "        -0.0070,  0.9478,  0.5055,  0.3603,  0.1713,  0.8405, -0.6487,  0.5961,\n",
       "         0.2438,  0.1746,  0.7702,  0.0023, -0.4498, -0.6129,  0.4206,  0.5447,\n",
       "        -0.2881, -0.8637, -0.9044, -0.5286, -0.7759,  0.6931, -0.1961,  0.1424,\n",
       "         0.8717, -0.0786, -0.6959, -0.4973, -0.4147,  0.1650, -0.3586, -0.7372,\n",
       "         0.8168, -0.1738, -0.4136,  0.1854, -0.4897,  0.4448,  0.0155, -0.8835,\n",
       "         0.6225, -0.1110,  0.3223, -0.2382, -0.5372, -0.3520, -0.7357, -0.1999,\n",
       "         0.6454,  0.5781,  0.6981,  0.7987, -0.3723, -0.6456,  0.8036, -0.6847,\n",
       "        -0.6025, -0.5890, -0.4712, -0.4884,  0.6916,  0.3243, -0.4839,  0.8455,\n",
       "         0.7450,  0.6438,  0.0972, -0.9415,  0.7268,  0.1009,  0.9284,  0.9697,\n",
       "         0.1939,  0.9659, -0.5167,  0.0996, -0.4650, -0.3468, -0.0086, -0.9762,\n",
       "         0.4141,  0.3483, -0.8163,  0.8616,  0.7401, -0.1202, -0.6676,  0.5029,\n",
       "        -0.4545, -0.3811,  0.1340,  0.9100, -0.8676,  0.2894,  0.2671, -0.1417,\n",
       "        -0.0477,  0.5695,  0.5229, -0.4995,  0.6805,  0.8898,  0.0868, -0.2499,\n",
       "        -0.9026,  0.7669,  0.3695,  0.6671, -0.2535,  0.7143, -0.2516,  0.2939,\n",
       "         0.0552,  0.7422,  0.9267, -0.1649, -0.3017,  0.0690,  0.1912,  0.2425,\n",
       "        -0.4659, -0.5383,  0.3078,  0.4102,  0.3906, -0.0847, -0.3471, -0.9548,\n",
       "         0.3479,  0.1935, -0.6142,  0.2315, -0.6812, -0.8428, -0.6592, -0.8371,\n",
       "         0.0799, -0.8670, -0.9293, -0.1868, -0.1716,  0.7072, -0.5376, -0.8663,\n",
       "        -0.4293, -0.0151,  0.3494, -0.3579, -0.5991, -0.8438, -0.6240,  0.3232,\n",
       "        -0.5819,  0.5964,  0.3742, -0.5707, -0.3640,  0.3865,  0.0781, -0.6656,\n",
       "        -0.8783,  0.6301, -0.7612, -0.5891, -0.4057, -0.1230, -0.1622,  0.0340,\n",
       "        -0.9860,  0.8315,  0.9631, -0.4053,  0.6443,  0.8863,  0.4399, -0.9968,\n",
       "         0.3678,  0.8668,  0.8919,  0.8228, -0.7740, -0.1915, -0.4553,  0.6958,\n",
       "        -0.3734,  0.0682,  0.1429, -0.3695, -0.2222,  0.0588, -0.9737, -0.7778,\n",
       "        -0.5741, -0.6474, -0.9087, -0.5789, -0.0285,  0.4306, -0.3988, -0.3620,\n",
       "        -0.5497,  0.6047, -0.3013, -0.4234, -0.0428, -0.2572, -0.6866, -0.4838,\n",
       "         0.0692,  0.6862, -0.4737,  0.3048,  0.7865,  0.5385, -0.8515,  0.8079,\n",
       "        -0.8398,  0.5408,  0.1274,  0.7446, -0.9555,  0.7983,  0.5003, -0.5231,\n",
       "         0.9328, -0.1833,  0.2376, -0.2740, -0.2322, -0.7559, -0.0488, -0.0917,\n",
       "        -0.1055,  0.7563, -0.5419, -0.4653,  0.3499,  0.0740, -0.2623,  0.9492,\n",
       "        -0.7639, -0.7815,  0.0491,  0.6929,  0.2113, -0.0819, -0.7883, -0.6202,\n",
       "        -0.6790, -0.8548,  0.4019,  0.3175,  0.7399,  0.4527, -0.8669, -0.2312,\n",
       "        -0.6037, -0.8328,  0.2644, -0.7508,  0.7337,  0.4235,  0.7774, -0.0344,\n",
       "        -0.8329, -0.9340, -0.3340,  0.8313, -0.7151, -0.0674,  0.4913,  0.0474,\n",
       "         0.0911, -0.2455,  0.4332,  0.8614, -0.2541, -0.8838, -0.5022,  0.1984,\n",
       "         0.5869, -0.9584, -0.5633, -0.9327, -0.9150, -0.0575,  0.2080,  0.2919,\n",
       "        -0.5140,  0.1110, -0.1527,  0.5321,  0.3202,  0.6953, -0.4606,  0.3439,\n",
       "         0.7983,  0.0375,  0.7433,  0.0732,  0.9460,  0.7958, -0.1310,  0.1321,\n",
       "        -0.5964,  0.6732, -0.3360, -0.5617,  0.9610,  0.4100,  0.7134,  0.0612,\n",
       "         0.9273, -0.5197, -0.2057, -0.9113,  0.9389,  0.9766, -0.8342,  0.5735,\n",
       "         0.4625,  0.6874, -0.1128, -0.1828, -0.0389, -0.1780,  0.9738, -0.3491,\n",
       "        -0.1991,  0.3733, -0.2237, -0.1920,  0.8154, -0.0893,  0.5257, -0.9881,\n",
       "        -0.2927, -0.0765,  0.7839,  0.8802, -0.3701,  0.6418,  0.1432,  0.9280,\n",
       "        -0.1427,  0.4019,  0.4111, -0.3044, -0.0567, -0.0353,  0.6567, -0.0537,\n",
       "         0.9650, -0.6582, -0.0648, -0.4379,  0.8868, -0.9779, -0.3283,  0.5407,\n",
       "        -0.3712,  0.8174,  0.3912,  0.9782,  0.9829, -0.4964, -0.8420,  0.0309,\n",
       "        -0.8382, -0.1590,  0.8096,  0.5136, -0.4373,  0.2432, -0.3688, -0.2304,\n",
       "        -0.9641, -0.7346, -0.4228, -0.1830,  0.5041, -0.8482,  0.4000, -0.4943,\n",
       "         0.5093, -0.8095,  0.8535, -0.9200, -0.6177, -0.1666,  0.5983,  0.8790,\n",
       "        -0.8698,  0.8058, -0.2526,  0.8710, -0.2504, -0.7534, -0.4989, -0.9805])"
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(N)*2 - 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = forward_pass_dif(x,a1,a2,a3,a4,w1,w2,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(445.8278, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 1729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = loss(x,y)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1730,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = tensor([1.8689]), a2 = tensor([299.4886]), a3 = tensor([-0.2547]), a4 = tensor([169.1209]), w1 = 167.9651336669922, w2 = 157.51023864746094\n"
     ]
    }
   ],
   "source": [
    "print(f'a1 = {a1.grad}, a2 = {a2.grad}, a3 = {a3.grad}, a4 = {a4.grad}, w1 = {w1.grad.abs().mean()}, w2 = {w2.grad.abs().mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = tensor([0.9345]), a2 = tensor([0.2995]), a3 = tensor([-0.2547]), a4 = tensor([0.2370]), w1 = tensor([ 6.1596e-02,  1.1576e-01,  3.6485e-01, -1.5096e-01,  1.7334e+00,\n",
      "        -7.3301e-02, -7.2116e-01, -1.4447e+00,  2.2265e+00,  1.6595e+00,\n",
      "        -2.5194e+00, -8.5395e-02, -2.1497e+00, -4.2662e+00, -7.1463e-01,\n",
      "        -3.6205e-01, -6.2151e-01, -4.4275e-01,  7.1217e-01,  7.4931e-01,\n",
      "        -1.0352e+00, -8.6107e-01,  4.0265e-02, -5.6640e-01,  4.9736e-01,\n",
      "        -1.4373e+00, -2.6841e+00, -1.1649e-01, -2.4010e-02,  1.9442e+00,\n",
      "        -1.0273e+00,  1.3778e+00, -1.0739e-01,  6.1562e-01,  1.9376e+00,\n",
      "         2.8567e+00,  2.3924e-01,  2.0818e+00,  1.7962e-01, -5.5108e-01,\n",
      "         4.3817e-01,  8.5331e-02, -3.3411e-02, -3.6631e-01, -9.7426e-01,\n",
      "         3.9662e-01, -6.3477e-01,  7.8097e-02,  2.8550e-01,  1.7111e+00,\n",
      "         2.5353e-01, -3.0644e-01, -9.4516e-01,  4.2973e-01, -3.2058e-01,\n",
      "        -1.8733e+00, -1.3475e+00, -2.1873e-01,  1.0338e+00, -8.3066e-02,\n",
      "        -2.7514e-01, -3.8480e-01, -4.0502e-03,  2.8977e-01,  8.4959e-01,\n",
      "        -9.8051e-01, -9.6197e-01,  6.0209e-01, -6.8454e-01, -1.1460e+00,\n",
      "         1.5482e-01,  9.1481e-02, -1.8745e-01, -4.7883e-02,  3.2502e-02,\n",
      "        -5.2509e-02, -1.3075e+00, -4.9556e+00,  4.5713e-01, -2.4462e-01,\n",
      "         1.8808e-01,  3.2755e-01, -7.0489e-02,  1.6537e+00, -2.8188e+00,\n",
      "         3.2395e+00, -4.9476e-01, -4.3673e-02, -5.8281e-02, -2.0421e-02,\n",
      "         9.6185e-02, -6.4549e-02,  1.8098e-01,  5.4351e-01,  7.1133e-01,\n",
      "         6.7125e-01,  3.8880e-01,  5.4438e-04, -3.0675e-01,  1.3753e+00,\n",
      "        -1.2560e+00, -5.9245e-01,  1.7097e-01, -7.3185e-01, -6.3765e-01,\n",
      "        -4.4313e-02, -2.8134e-03, -2.9418e-01, -2.7776e-01, -1.2639e+00,\n",
      "         2.3124e-01, -8.2376e-01,  7.5137e-02,  1.0177e+00, -3.2329e-01,\n",
      "         5.1018e-01,  3.6472e-01,  3.6357e-01,  3.6061e-01,  3.0049e-01,\n",
      "         8.9644e-01,  8.5191e-01, -1.5469e-01, -5.0088e-01,  1.2173e+00,\n",
      "         3.5843e-02, -8.4523e-01,  5.8901e-01,  1.0107e+00, -1.1965e-02,\n",
      "        -9.5728e-01, -6.6860e-01, -3.1604e-03, -1.5072e+00, -3.9746e-01,\n",
      "        -1.4797e-01,  3.3298e-01,  6.0993e-01, -1.3692e+00,  3.3038e-01,\n",
      "         9.9570e-01, -6.9647e-01, -6.9205e-01,  1.2475e+00,  9.3179e-01,\n",
      "        -1.1897e-01, -3.7090e-02, -7.6762e-01, -2.8541e-01,  3.5429e-01,\n",
      "         4.5398e-01,  2.3940e+00,  1.1406e+00, -3.6512e+00,  3.9007e-01,\n",
      "        -7.3489e-02,  4.6765e-01, -3.0903e-01,  4.1754e-02, -2.7145e+00,\n",
      "        -7.4548e-02,  7.1145e-01,  7.7851e-02,  1.7660e-03, -1.4306e-01,\n",
      "         1.9020e-01, -1.3239e-01,  5.9868e-01,  1.9715e+00,  1.1791e+00,\n",
      "         8.5061e-01,  5.1827e-01,  7.9043e-01,  2.7797e-04, -7.6231e-02,\n",
      "         5.1203e-02, -3.4305e-02, -1.9409e-01, -2.9624e-01, -6.6919e-01,\n",
      "        -6.7939e-02,  8.7091e-01,  1.1579e+00, -1.1992e+00,  1.1874e-01,\n",
      "        -1.8637e+00, -1.8436e-02, -2.0717e-01, -1.4751e+00,  9.4935e-01,\n",
      "         1.1154e-01,  3.2744e+00,  4.1947e-01, -7.2364e-01,  3.7965e-02,\n",
      "         1.6222e+00,  7.6612e-01,  2.4376e-01,  8.9266e-01,  4.5964e+00,\n",
      "        -2.9424e+00,  2.7712e+00, -1.8608e+00, -3.8880e-02, -1.0084e-01,\n",
      "        -6.1970e-02,  1.1055e-01, -6.4247e-02, -2.4966e-01,  4.6562e-01,\n",
      "         1.2260e+00, -2.4388e-01,  3.2837e-01, -3.3657e-01, -2.1233e-01,\n",
      "        -1.5227e+00, -7.7362e-01, -3.6089e+00, -6.3672e-01, -6.0663e-01,\n",
      "         4.1158e-01, -1.1606e-02, -1.6649e-01, -5.3851e-02, -3.4008e-01,\n",
      "        -8.9430e-01, -3.3257e-01,  2.1786e-03, -5.2817e-02,  1.1822e+00,\n",
      "        -1.5132e+00,  6.4420e-02, -2.0965e+00, -2.6959e-02, -1.3807e-02,\n",
      "         5.8153e+00,  5.4054e+00,  2.0492e-01, -3.0655e-01, -7.1578e-01,\n",
      "        -9.0090e-01, -7.0175e-01, -9.0907e-01, -7.8847e-01, -6.8825e-02,\n",
      "        -1.5687e-01,  6.6365e-01,  4.3966e-01,  4.7276e-02,  1.7087e+00,\n",
      "        -1.3220e+00,  3.3323e-01, -1.7490e-01, -4.4221e-01, -2.5371e-01,\n",
      "         6.9538e-01, -6.4115e-01,  7.2672e-01, -8.7819e-01, -1.2065e-01,\n",
      "        -1.9503e+00,  7.9039e-01, -1.5419e-01, -8.3040e-01, -4.3975e-02,\n",
      "        -2.2923e-02, -8.3950e-02,  6.5976e-01, -9.0545e-01,  7.3205e-02,\n",
      "        -5.8312e-02, -3.9489e-03, -6.6253e-01,  3.4402e-03, -5.6555e-01,\n",
      "         1.9967e-01, -8.3800e-02, -1.1926e-02, -6.8125e-01,  4.3322e-01,\n",
      "         6.0832e-01,  4.2327e-02, -2.1664e-02, -2.6524e-03, -1.7437e-02,\n",
      "         2.0043e-01,  1.3265e+00, -1.3720e-01, -5.4130e-01, -6.0617e-01,\n",
      "        -1.0934e+00,  3.5714e-01, -1.0588e-02,  1.7220e-01,  5.9560e-02,\n",
      "        -2.0067e-01, -1.5535e-01,  4.7751e-02,  1.5461e-01, -1.4307e-01,\n",
      "         3.7936e-02, -2.7055e-02,  4.3444e-02,  5.3501e-02, -2.0532e-02,\n",
      "         1.6890e-01,  1.9617e-01,  3.7262e-03, -7.4582e-01,  4.7210e-01,\n",
      "         7.6822e-02, -3.6507e-01,  1.0394e-01,  1.3815e-01,  2.1873e-01,\n",
      "        -5.5520e-01, -1.4787e-01, -1.1575e+00, -5.7509e-01, -1.1950e-01,\n",
      "        -3.1389e-01,  4.4630e-02, -1.4132e-01,  2.3584e-01, -2.5281e-01,\n",
      "        -1.1867e-01,  1.0266e-01,  8.1266e-02,  1.4131e-01,  1.4247e+00,\n",
      "         4.2061e-01, -1.8631e-01,  1.3328e-01, -1.6732e+00, -2.7437e+00,\n",
      "        -1.5700e+00,  4.8594e+00, -3.2157e-01, -2.6376e+00,  8.9619e-01,\n",
      "         1.0023e-01,  8.6920e-01,  1.0241e+00,  8.2227e-01,  7.0387e-01,\n",
      "         1.1189e+00,  5.7663e-03, -9.0237e-01,  3.7245e-01, -7.1203e-02,\n",
      "        -4.0396e-01,  4.4962e-03, -1.3218e-01,  3.4875e-01,  6.7232e-02,\n",
      "         8.5522e-02, -5.7095e-02,  1.4086e+00,  7.4387e-01,  8.3914e-01,\n",
      "         7.4660e-01,  1.6636e+00,  1.1114e-01,  9.2878e-02,  6.0775e-02,\n",
      "        -2.3825e-01,  1.6436e-02,  3.5506e-01,  4.9491e-01,  9.8514e-01,\n",
      "         1.0047e+00,  1.7136e-01, -8.0838e-01,  9.8646e-02,  5.0756e-01,\n",
      "         1.4020e+00, -7.3407e-01,  8.7835e-01, -2.2408e+00, -2.3885e+00,\n",
      "         1.1674e+00, -4.7790e-01, -9.4676e-01, -3.4773e-01,  2.9359e+00,\n",
      "        -9.1190e-01,  3.7853e-02,  1.7919e+00,  3.1254e+00,  5.4013e-02,\n",
      "        -1.3195e+00, -1.9724e-01, -2.4571e-01, -1.0081e-01, -5.5141e-01,\n",
      "         1.6184e+00,  2.2936e-01, -2.4186e-01,  4.7587e-01, -3.0256e-01,\n",
      "        -1.3903e-01, -9.1415e-02, -4.9677e-02, -2.0251e-01, -4.6231e-01,\n",
      "         6.1356e-01,  4.0221e-01, -9.8597e-01, -8.9133e-01, -1.3335e+00,\n",
      "         2.1254e-02,  2.7703e-02,  2.4898e-01,  2.0150e-01,  1.6022e-01,\n",
      "        -8.1524e-02,  1.2980e-01, -5.1849e-01, -6.9338e-02,  8.4617e-01,\n",
      "        -8.3939e-01,  7.2894e-02,  2.4861e-01,  1.7133e-01, -1.8900e-01,\n",
      "        -4.6147e-03,  6.5640e-02,  2.4762e+00,  2.0940e+00,  6.3459e-01,\n",
      "        -8.3442e-01, -4.7467e-01, -1.1029e+00, -1.9818e-02,  1.3637e+00,\n",
      "         1.2952e+00, -6.2910e-01, -1.4879e+00, -8.9867e-01,  2.9117e-01,\n",
      "         4.6372e-01, -2.4861e-01, -4.6406e-01, -1.3217e-01, -8.2107e-01,\n",
      "         7.9080e-01, -1.5980e-01,  6.3347e-01,  6.7398e-02,  1.9780e-01,\n",
      "         3.1852e-01, -2.9697e+00, -2.6212e+00,  3.1067e-01,  7.3466e-01,\n",
      "         1.0148e-01,  1.7222e+00,  3.2522e-01, -8.5699e-02,  4.7073e-02,\n",
      "         9.9878e-02,  3.8378e-01,  1.3572e+00,  2.4726e+00,  7.3158e-01,\n",
      "        -3.1479e+00,  9.7194e-01,  1.4274e-02, -5.9178e-02, -5.1726e-01,\n",
      "        -7.0561e-01,  6.0030e-01,  1.5348e+00,  1.4485e-01,  4.2798e-01,\n",
      "         2.0421e+00, -5.0109e-01,  9.5672e-02, -2.7926e-01,  3.9986e-01,\n",
      "        -1.1692e-01, -8.8795e-02,  7.2215e-01,  2.7440e-02, -4.8861e-02,\n",
      "         7.4416e-02, -6.8133e-01, -2.2631e-01,  2.3069e-01, -9.1117e-01,\n",
      "         7.2053e-01, -4.6713e-02,  1.9014e+00,  8.5472e-01,  2.6997e-01,\n",
      "        -1.2446e+00, -6.0050e-01, -2.3597e+00, -9.5918e-01,  1.7057e-01,\n",
      "         1.1883e+00, -1.9608e-02, -1.7704e+00,  3.2098e+00,  1.2839e-01,\n",
      "         3.6530e+00,  5.3150e-01,  1.6414e+00,  2.2147e+00, -7.4173e-02,\n",
      "         4.0677e-02, -4.6646e-01, -4.8343e-05,  1.0490e-01,  2.3758e+00,\n",
      "         2.2858e+00, -7.3835e-01, -9.2802e-01, -6.9839e-01, -6.2990e-01,\n",
      "        -5.1631e-01, -5.3032e-01,  4.0204e-01,  3.4884e-01, -2.9369e-01,\n",
      "         2.3735e-01, -8.7229e-02,  1.0949e-01,  5.6608e-02,  3.3993e-04,\n",
      "        -8.8758e-02,  5.7126e-03,  1.3577e-01, -3.1211e-01, -3.3848e-01,\n",
      "        -1.5616e-01, -2.5874e-01, -4.8784e-02, -9.6576e-01,  1.2986e+00,\n",
      "         2.9815e-02, -6.2158e-01, -2.9666e-01,  1.0133e-01,  1.3278e-01,\n",
      "        -1.9001e-02, -1.5193e-01, -1.1736e+00, -1.6870e-01,  3.9281e-01,\n",
      "         1.6213e-01, -2.1068e-01, -2.4836e-02, -4.2893e-01, -1.2367e+00,\n",
      "        -1.8866e+00,  2.4815e-02,  3.4890e-01, -1.0158e+00,  4.0671e-02,\n",
      "        -2.3122e-02,  8.2212e-02,  4.0181e-01, -4.3716e-01,  6.0427e-02,\n",
      "        -3.2324e-01, -2.1180e-01,  1.2651e-01,  3.6476e-01,  1.4078e-01,\n",
      "        -4.6993e-01,  4.2069e-01,  2.4265e-01, -2.0358e-01, -4.1463e-02,\n",
      "         6.3344e-03,  1.6866e-01,  2.7217e-01, -7.5113e-01, -2.4323e-01,\n",
      "        -3.7455e-03, -9.7919e-02, -1.9603e-01,  1.4144e-02, -2.2376e-02,\n",
      "         5.6204e-02, -3.9730e-01,  2.1890e-01,  2.9330e-02, -3.1481e-03,\n",
      "         4.9723e-01,  1.1221e+00, -1.8586e+00, -5.9078e-02,  8.7574e-01,\n",
      "         2.6153e-01,  3.1669e-01, -1.8708e-01,  1.1961e-01,  9.4585e-02,\n",
      "         1.4691e-01,  3.4499e-02, -5.5822e-01,  1.6529e+00,  6.2378e-01,\n",
      "         2.0697e-01, -3.2468e-01,  2.0161e-01, -6.1584e-02,  5.1053e-01,\n",
      "         4.6412e-01, -1.1501e+00, -4.6710e+00,  1.1014e+00,  9.4625e-01,\n",
      "         1.3715e+00,  8.4792e-01,  1.4052e+00,  2.1612e-01, -1.9819e+00,\n",
      "        -2.6899e+00,  1.0888e+00,  1.1424e+00, -1.0422e+00,  2.4220e-01,\n",
      "         1.6269e-01,  4.3582e-01,  2.0256e-01, -2.9504e-02,  3.5428e-01,\n",
      "        -4.5957e-02,  5.6278e-02, -2.0143e+00, -9.6668e-01, -5.0714e-01,\n",
      "        -1.3358e-01, -4.2684e-01, -2.8882e-01,  7.5422e-02,  2.2600e-01,\n",
      "         5.7171e-02,  6.1092e-02,  4.8413e-02,  7.2784e-01,  7.7113e-01,\n",
      "        -3.2377e-02, -8.1298e-01, -4.8492e-02,  1.4749e-01,  2.9366e-01,\n",
      "         2.3070e-02, -1.5553e-02, -1.7310e-01,  9.1022e-02, -9.5148e-02,\n",
      "        -6.0227e-01, -1.4439e+00, -2.6992e-01,  1.8332e-01,  1.5199e-01,\n",
      "        -5.8165e-01,  4.4872e-01, -3.7730e-02,  3.5560e-01,  1.1255e+00,\n",
      "         8.2747e-02, -3.7298e-01, -2.0831e-01, -4.1631e-01, -6.0696e-01,\n",
      "         1.0159e-02, -5.8297e-05, -1.4885e-01, -1.4489e+00,  2.5799e-01,\n",
      "         8.3766e-02, -1.7180e-01, -3.3915e-02, -1.3596e-01,  9.1223e-02,\n",
      "         6.2791e-01,  1.8186e+00, -1.5807e+00,  1.6359e-01,  7.8806e-01,\n",
      "        -2.9176e-02,  2.9107e-01,  1.7541e-01,  1.1072e-01, -1.6462e+00,\n",
      "         2.5757e-01,  3.9382e-01, -2.5500e+00, -1.4400e+00, -2.5594e-01,\n",
      "        -6.6106e-01,  4.0797e-01,  1.9315e-01, -1.7062e-01, -6.4543e-01,\n",
      "        -9.7175e-02, -8.8617e-02, -2.6175e-01, -1.3362e-01, -4.7104e-01,\n",
      "        -2.5256e+00, -1.6556e+00,  7.7981e-01, -1.1962e+00, -1.2499e+00,\n",
      "        -5.4544e-01,  3.8156e-01, -1.5073e+00, -5.5408e-02,  7.1330e-02,\n",
      "         2.0555e-02, -9.9604e-01, -1.0874e+00,  1.1533e+00,  1.7119e-01,\n",
      "        -2.0090e-02, -1.5886e+00,  2.1596e-01, -9.8706e-02,  1.5457e-01,\n",
      "        -3.4390e-02, -1.2151e-01, -2.5659e-02, -1.2136e-03,  2.3680e-01,\n",
      "         2.5042e-01,  6.6184e-02, -3.2507e-02, -8.0523e-02, -7.4321e-02,\n",
      "        -7.9128e-02,  5.8403e-01, -6.3480e-02,  4.3219e-02,  3.4328e-01,\n",
      "        -5.0535e-03, -2.6878e-02, -2.0788e-01, -8.1292e-02, -1.7014e-01,\n",
      "        -4.9006e-01, -9.5191e-01, -3.0005e-01,  1.0477e+00, -2.2090e+00,\n",
      "        -2.1953e-01,  5.6874e-01, -2.4729e-01, -4.6873e-01,  8.4648e-01,\n",
      "        -3.8370e-01,  2.4645e-01, -7.8567e-01, -1.0780e-01,  4.8728e-02,\n",
      "         5.0091e-02, -3.7010e-01, -3.8932e-01, -3.0733e-01, -8.0845e-02,\n",
      "         4.2659e-01, -2.2996e+00,  1.1410e+00,  4.0799e-01, -1.7222e-02,\n",
      "        -6.7382e-02,  6.2268e-01, -5.6485e-01,  1.7248e-01, -1.1278e+00,\n",
      "        -2.3749e-01,  1.3971e+00,  3.8389e-01, -5.5992e-03,  2.2789e+00,\n",
      "         1.4476e+00, -5.4323e-01,  8.1534e-01,  7.8611e-01,  4.3381e-02,\n",
      "         5.3951e-01,  1.0685e-02,  4.4243e-01, -1.3907e+00, -4.4608e-01,\n",
      "         6.9505e-01,  3.3029e-01,  3.5855e+00, -1.6875e+00,  2.0850e-01,\n",
      "        -6.4439e-01,  3.0487e-02, -5.0037e-01,  6.6251e-01,  1.0790e+00,\n",
      "         5.5319e-01, -4.4102e-02,  1.9388e+00,  5.7733e-01, -3.6512e+00,\n",
      "         1.2625e+00, -4.3009e-01, -7.4924e-02, -3.8277e-02,  2.7204e-01,\n",
      "        -3.1770e-01,  2.5437e-01,  3.9021e-01, -2.4059e-01, -7.3268e-02,\n",
      "        -1.1995e-01,  4.7389e-01, -1.9241e+00, -1.9382e-02,  6.3887e-01,\n",
      "        -8.0964e-01, -1.2291e+00,  1.7167e+00,  4.1715e-01, -1.1230e+00,\n",
      "         5.4558e-01,  4.3895e-01,  3.5098e-01, -2.4183e-02,  7.8923e-02,\n",
      "         1.3380e-02,  2.2750e-01,  3.6843e-01, -9.4846e-02,  1.5931e-04,\n",
      "         1.0892e-02,  1.4592e+00,  1.6707e+00,  6.0997e-01, -9.7393e-01,\n",
      "        -1.0266e+00, -5.2233e-01, -3.7524e-02,  2.9617e-01,  1.0649e-01,\n",
      "        -1.0256e+00, -1.6363e+00, -2.1824e+00,  1.3885e-01, -3.0133e-01,\n",
      "         2.1763e+00,  3.7636e-02, -7.7223e-03,  1.6401e-01,  4.3896e-01,\n",
      "        -2.3717e-01, -9.5654e-01,  4.2877e-01,  2.8538e-01,  4.2920e-01,\n",
      "         9.5549e-01, -8.7136e-01,  3.2648e+00,  2.9797e+00, -1.0674e+00,\n",
      "         7.2462e-02,  5.5728e-01, -5.7620e-01, -6.4225e-01,  3.0191e+00,\n",
      "        -1.1287e+00,  1.5097e+00, -7.2713e-03,  1.4758e+00,  1.7563e+00,\n",
      "         2.8424e-01,  1.9767e-02,  2.2608e+00,  5.0987e+00, -8.2182e+00,\n",
      "        -1.3751e+00, -2.9525e-01, -1.5612e-01, -4.8623e-01, -1.7617e-01,\n",
      "        -3.2979e-01, -8.0540e-03, -5.0401e-02, -5.1531e-01, -4.0606e-01,\n",
      "        -1.2336e-01,  2.1694e-03, -1.8717e-01, -1.3737e-01, -6.4561e-01,\n",
      "         3.5494e-01, -1.7475e+00, -1.9163e-01, -2.4760e-01,  9.9440e-01,\n",
      "        -4.8553e-01, -4.2983e-02, -2.5755e-01,  3.7860e-01, -9.8071e-01,\n",
      "        -1.0489e+00, -2.1107e-01, -2.7097e-01,  7.4061e-02, -1.2602e+00,\n",
      "         4.1414e-02,  3.2728e+00,  3.7855e+00, -2.9213e+00, -3.0219e+00,\n",
      "         4.6155e+00,  3.4657e+00, -6.5792e+00,  2.0979e+00,  1.5832e+00,\n",
      "        -5.7593e-02, -1.4340e-01, -3.3075e-01, -8.7086e-01,  1.4766e-01,\n",
      "        -3.7241e-02, -3.8037e-02,  9.5303e-01,  9.0988e-02,  4.7453e-01,\n",
      "         2.4147e+00,  2.1757e+00, -2.6861e+00, -2.6466e+00, -7.1089e-01,\n",
      "        -3.7173e-02, -4.8638e-02,  1.8962e-01, -3.0795e-01, -4.3199e-01,\n",
      "        -2.8672e-01, -3.0727e-01,  7.9608e-01,  1.0689e+00,  7.7929e-01,\n",
      "        -9.8882e-01, -1.0328e+00, -4.4511e-03, -3.4580e-02,  5.3313e-01,\n",
      "        -1.5672e-01,  2.4666e-01,  1.6745e-01,  2.4143e-01, -4.4645e-01,\n",
      "         2.5193e-01,  3.4430e-02, -4.9946e-01, -3.7799e-01,  7.0005e-01,\n",
      "         5.6593e-01,  1.4911e-02,  1.4156e-01,  1.1272e+00,  5.5327e-02,\n",
      "        -1.4615e-01, -3.9285e-01, -9.2375e-02,  3.6917e-01,  2.3591e-02,\n",
      "         2.4717e-02, -1.8404e-02,  3.2208e-02,  4.0920e-02,  1.8156e-01,\n",
      "         1.0545e-01, -1.0442e+00,  2.6679e-01, -1.0796e-01, -4.5632e-01,\n",
      "        -9.9144e-01, -2.3752e-02,  2.7928e-01, -8.5371e-02,  2.3715e-01,\n",
      "        -6.6509e-01, -2.2207e-02, -5.2571e-01, -5.8255e-01, -8.0896e-01,\n",
      "         1.3629e-02, -8.0294e-03, -2.3063e+00,  4.7929e-01, -1.1657e-01,\n",
      "        -1.2797e+00, -1.2374e+00, -3.9164e-02, -4.6135e-01,  5.2460e-01]), w2 = tensor([-4.2545e-01, -2.1669e+00,  1.1470e+00, -3.7421e+00,  6.9870e-01,\n",
      "        -9.5561e-01, -3.2946e+00, -8.2923e-02, -6.7229e-03, -8.6332e-01,\n",
      "        -1.6125e+00,  8.0577e-02,  1.3661e+00, -1.1072e-01, -4.1721e+00,\n",
      "         1.1152e+00, -4.0787e-01,  4.4896e-02, -8.9051e-01,  3.7465e-01,\n",
      "        -9.6849e-01, -8.8604e-01,  8.0406e-01,  1.1791e+00,  2.8935e+00,\n",
      "         2.2474e+00,  3.2790e-01,  2.3457e-01,  2.4190e-01,  1.8838e+00,\n",
      "         1.6527e+00, -1.0554e+00, -1.9268e+00,  2.2310e-01, -6.6699e-01,\n",
      "         8.7898e-01, -1.5790e+00, -2.0654e+00,  1.3462e+00,  1.4061e+00,\n",
      "         7.2733e-03, -8.0848e-01,  1.0594e+00,  1.8758e+00, -3.7898e-02,\n",
      "        -6.1273e+00, -6.5527e+00, -2.9692e+00,  1.1432e+00,  9.8542e-03,\n",
      "        -9.5464e-01,  2.8646e+00, -2.3865e+00,  1.5805e+00, -3.1066e+00,\n",
      "        -6.7427e-01, -7.5546e-01,  1.6576e-01, -1.1522e+00,  7.5251e-01,\n",
      "        -7.3855e-01, -2.2846e+00,  1.1522e+00, -1.9423e+00,  1.9289e+00,\n",
      "         1.5862e+00, -3.5036e+00, -1.5753e+00,  8.5007e-01,  3.2174e-02,\n",
      "        -3.8790e-01,  4.8879e-02, -1.0754e+00, -3.3492e-01,  1.5227e+00,\n",
      "         1.8725e+00,  2.5678e+00,  1.9092e-02,  6.5168e-01, -3.0190e-01,\n",
      "        -1.4609e+00, -6.1309e-01, -6.7982e-02,  5.3301e-01, -2.7721e+00,\n",
      "         2.4667e+00, -1.7259e+00,  5.6088e-01, -4.4697e-01, -9.6734e-01,\n",
      "        -1.1143e+00, -7.8333e-01, -1.4258e+00,  3.8396e+00,  1.9602e+00,\n",
      "         1.8575e-01, -5.3169e-01,  4.7224e+00,  2.3259e+00,  1.4901e+00,\n",
      "         1.8213e+00, -1.2239e+00, -2.4076e-01, -2.6265e+00,  1.6279e-01,\n",
      "        -7.7186e-02, -1.9261e-01, -4.5417e-01, -1.5839e-01, -6.2720e-01,\n",
      "         8.8603e-01, -2.4494e-01, -7.9982e-01,  2.3676e+00, -3.9494e+00,\n",
      "        -1.0775e-01,  1.8040e-01, -3.8093e-04, -6.5805e-04, -2.0166e-01,\n",
      "         3.1110e-01,  4.3462e-02, -1.4077e+00,  1.4974e+00, -1.5408e+00,\n",
      "        -1.5714e+00, -1.3853e+00,  3.7229e+00, -3.2627e+00,  3.3524e+00,\n",
      "        -4.8212e+00, -4.3985e+00,  1.7618e+00, -1.0004e-01, -4.0553e+00,\n",
      "         9.4392e-01, -3.2306e-01, -2.0816e-01, -7.0301e-01, -1.6008e+00,\n",
      "         1.2438e-01, -2.1384e-01, -1.7745e-01,  3.0405e+00, -4.2010e-01,\n",
      "        -2.0085e+00,  2.0742e-01,  6.6720e-03,  7.1977e-01,  1.6050e-01,\n",
      "         5.1668e-02,  4.8673e+00, -2.6648e+00, -2.8949e+00,  1.2207e+00,\n",
      "        -6.4796e-01, -4.1732e-02,  8.1898e-01,  4.8878e+00,  1.1921e+00,\n",
      "        -4.1261e-02, -3.8273e-02, -6.3165e-01, -1.0724e+00, -2.2756e-01,\n",
      "        -1.9110e+00, -2.6372e+00, -1.4653e+00,  4.9812e-01,  8.0903e-01,\n",
      "        -2.7548e+00, -1.9040e-01, -1.4269e+00,  1.6928e+00,  1.7069e-01,\n",
      "        -4.8799e-01, -1.3433e+00,  1.2326e-01, -5.5523e-01,  1.3510e-02,\n",
      "        -2.9906e+00,  9.1293e-01,  5.3173e-01, -1.3855e-01,  8.3162e-01,\n",
      "         5.6815e-01,  2.1016e+00,  2.2337e+00, -2.9914e+00, -3.1035e+00,\n",
      "        -5.0139e+00, -1.5042e+00,  4.4780e-01, -7.6157e+00, -3.4973e+00,\n",
      "        -3.0676e+00, -2.1827e+00,  4.4668e+00, -2.9535e+00, -3.3156e+00,\n",
      "         1.0351e+01, -1.6280e+00, -5.1539e+00,  1.2722e-01,  2.0700e+00,\n",
      "         6.1597e+00, -8.0323e-01,  5.4822e-01, -1.2157e+00, -6.0113e-02,\n",
      "         2.9546e-01,  1.3822e-02, -1.3198e-01, -4.0916e-02,  2.9100e-01,\n",
      "        -3.5640e-01,  2.3745e+00, -2.7653e+00, -7.8328e-01,  1.6479e-01,\n",
      "        -2.0801e+00,  2.3109e+00,  2.8693e+00,  1.7422e+00, -1.5036e+00,\n",
      "        -6.3909e-01,  1.0812e-01,  1.9139e+00, -1.8348e+00,  4.2284e-01,\n",
      "         6.3569e-01, -4.0098e-01,  1.4771e+00, -1.2673e+00, -4.6499e-01,\n",
      "         8.8000e-01, -1.1489e+00, -5.8361e+00,  4.5124e+00, -1.8331e+00,\n",
      "        -2.2512e+00,  2.6765e+00,  3.2394e-01, -2.0944e+00, -3.1191e-01,\n",
      "        -1.9660e-01, -3.3938e-02, -1.3285e+00, -1.6961e+00,  3.6055e+00,\n",
      "         1.2117e+00, -6.1890e-01, -1.3892e+00, -1.2596e-01,  1.0881e+00,\n",
      "        -3.0922e-01, -1.5563e+00,  1.9457e+00, -2.8058e+00,  4.0718e+00,\n",
      "         2.0609e+00, -1.7235e-01, -3.9991e-01,  8.0151e-01,  9.7524e-01,\n",
      "        -4.7852e-01,  1.1101e-01, -3.1793e-01,  7.8010e-03,  1.6045e+00,\n",
      "         6.6637e-01,  2.7823e-02, -1.6947e-02,  7.1463e-01, -5.5443e-01,\n",
      "         1.0667e+00, -3.9842e-02,  1.2869e-02, -1.9473e-01, -3.5640e+00,\n",
      "        -8.7453e-01, -2.1251e-01, -7.9932e-02,  3.6384e-01, -1.8328e-01,\n",
      "        -1.0015e-01,  1.1949e+00,  4.1547e+00,  3.2471e-01,  5.9362e-01,\n",
      "         1.6282e-02,  1.9917e-02,  1.9220e-01,  3.1553e-01, -4.8192e-01,\n",
      "         7.4049e-01,  4.2829e-01, -1.8506e+00,  4.3775e-01,  1.1933e+00,\n",
      "         9.0472e-01,  7.7767e-02,  9.4619e-02,  4.3746e-03,  3.5144e-01,\n",
      "        -2.2191e-01,  4.7416e+00,  5.0704e+00,  3.5084e+00,  2.0435e-02,\n",
      "        -8.4296e-01,  6.8543e-01,  6.6595e-01,  2.5181e+00,  1.4038e+00,\n",
      "        -4.5718e+00,  5.7687e-01, -1.0352e+00,  9.4851e-01,  1.8001e-02,\n",
      "        -5.6460e-02, -1.5095e-02,  1.6074e+00, -6.4557e-03, -6.5728e-01,\n",
      "        -1.2321e+00,  3.4065e-01, -8.2818e-02, -1.2479e+00,  5.4186e-01,\n",
      "        -4.0224e+00, -6.2906e-01,  5.2402e+00,  2.3405e+00,  6.8411e-01,\n",
      "        -3.2109e+00,  2.5403e+00, -1.6411e+00,  5.4565e-01,  6.3998e-01,\n",
      "         1.7688e+00,  1.8561e+00,  2.7679e+00,  4.8612e-02, -1.3418e-01,\n",
      "         7.4079e-01, -1.9710e+00, -2.2361e-01, -1.4727e+00,  4.2802e+00,\n",
      "         1.3186e+00, -2.6085e+00, -3.8211e+00, -1.6230e-01, -2.2633e-01,\n",
      "         1.0644e-01, -3.7993e+00,  5.8934e+00, -4.7392e+00, -4.4474e+00,\n",
      "        -2.9291e-02, -6.5462e-01, -3.7027e+00, -1.5006e+00,  1.3079e-02,\n",
      "        -4.7464e-01,  4.0005e-02,  3.0480e-03,  3.6454e-02,  2.7815e-03,\n",
      "         1.0152e-01, -5.2381e+00, -6.3934e-01,  1.1259e+00,  7.8937e-01,\n",
      "        -8.2180e-01, -2.9335e+00, -1.7129e+00,  1.2750e+00, -2.1764e+00,\n",
      "         7.3548e-01, -9.7763e-01, -3.8541e+00,  1.8077e+00,  1.6857e+00,\n",
      "         2.2617e+00,  4.3660e-02,  2.2423e+00, -2.2758e-01, -1.9284e+00,\n",
      "        -1.6516e+00,  9.3932e-01, -9.8606e-01, -6.1476e-01,  8.6049e-01,\n",
      "         4.2414e-01, -1.2088e-01,  1.2673e+00, -3.1935e-01,  6.9953e-02,\n",
      "         1.8600e-02,  2.1364e-01, -7.0811e-01, -2.3943e+00,  6.0213e+00,\n",
      "         3.7149e-01,  2.8395e-01, -3.7906e-02, -4.2385e-01,  2.6880e-01,\n",
      "        -4.2848e-01, -6.0576e-01, -3.7479e-02, -9.6114e-01, -1.0377e+00,\n",
      "         3.0546e-01, -4.2740e-02,  1.7180e-02,  6.3912e-01,  3.1581e-02,\n",
      "        -2.0434e-01,  1.8865e+00, -7.9889e-02, -1.3012e-01, -3.2053e-01,\n",
      "        -8.2603e-01, -2.9236e+00,  1.8242e-01, -2.3248e+00, -1.1540e+00,\n",
      "        -5.7272e-01, -3.4243e-02,  2.3415e-01,  3.6416e+00,  2.7758e+00,\n",
      "        -1.3210e+00, -8.3770e+00,  1.1114e+00,  1.8723e+00,  2.0016e+00,\n",
      "        -2.1040e-02, -1.0091e+00,  1.8946e-02,  1.5052e+00,  2.9264e-01,\n",
      "         8.3064e-02,  1.1204e-02,  9.9470e-03, -5.2597e-01, -2.5442e-01,\n",
      "         2.1790e+00, -2.1182e+00, -4.4984e+00,  2.3115e-01,  2.1352e+00,\n",
      "         1.5564e-01,  1.5538e+00,  6.0552e-02, -1.4575e+00, -9.3733e-02,\n",
      "         2.0826e-01, -2.7968e+00,  1.4784e-01,  1.4032e+00,  1.8891e+00,\n",
      "        -1.1155e-01, -2.1543e-01, -8.8354e-01,  9.2016e-01, -1.2665e+00,\n",
      "         3.1209e-01, -3.6942e+00, -1.1051e+00,  5.9812e-01,  1.1296e+00,\n",
      "        -1.9783e+00, -3.9930e+00, -5.0472e-01,  2.7387e-01,  4.2199e-01,\n",
      "        -9.9150e-02, -3.8091e-02, -5.4313e-01, -1.0183e+00,  3.4787e-01,\n",
      "         9.5045e-05,  3.8069e-01,  1.6381e+00, -2.0287e+00, -4.1073e+00,\n",
      "         4.4257e+00, -1.0788e+00,  2.8243e-01, -1.7250e-01, -1.7658e+00,\n",
      "         6.8328e+00,  3.3794e+00, -6.5999e-01, -2.8854e+00, -7.8991e-01,\n",
      "        -2.8284e-01, -1.9148e+00,  1.2997e-01,  3.0160e+00, -1.2130e+00,\n",
      "         3.0168e+00, -5.9074e+00, -1.9054e+00, -2.0057e-01, -5.9515e+00,\n",
      "        -2.4656e-01,  1.6907e+00,  1.4517e+00, -4.0741e-02, -8.8443e-01,\n",
      "         1.9504e+00,  9.6399e-02,  1.1177e+00, -1.0243e+00, -2.0031e+00,\n",
      "        -1.0857e+00, -1.1625e+00, -1.7332e-01,  2.2282e-01,  3.8250e-01,\n",
      "        -5.3281e-02,  1.3810e-01,  2.7145e-01, -2.6237e-01, -5.7931e-01,\n",
      "         4.8382e-01,  1.0518e-01,  1.8838e+00,  1.6543e+00,  1.6043e+00,\n",
      "         1.5405e+00, -2.3099e+00, -9.3224e-01, -5.5244e-02, -6.7441e-01,\n",
      "         1.3916e-01, -9.4062e-01,  2.3588e-01, -1.5813e-01, -2.9476e-01,\n",
      "         2.2045e+00,  2.4274e+00,  1.3618e-02, -3.7070e-01,  1.7698e+00,\n",
      "         4.3466e+00, -1.7149e+00,  2.3234e-01, -3.9309e-01,  3.3897e+00,\n",
      "        -2.4145e+00, -7.8989e-02,  2.4212e-01, -9.2410e-02,  5.4291e-01,\n",
      "         5.3179e-02,  9.1591e-03, -2.8137e-04,  2.7082e-02, -1.8153e-01,\n",
      "         8.5924e-01,  2.4826e-01,  2.1860e-01, -3.4929e-01, -5.7455e-01,\n",
      "        -1.1731e-02,  2.2652e-01,  1.6913e+00, -4.3407e-01,  1.1314e+00,\n",
      "         1.7148e+00, -1.1758e+00,  1.2904e+00, -5.1041e-01, -1.0542e-02,\n",
      "        -8.1130e-01, -4.5240e+00,  2.5298e+00, -7.4658e-01, -1.3868e-01,\n",
      "         2.7975e-01, -2.6734e-01,  7.2660e-01, -4.1255e-01, -1.1351e+00,\n",
      "        -6.9938e-01,  6.6340e-01, -1.6562e+00,  3.3734e-01, -6.0582e-01,\n",
      "         2.5599e-02,  2.1423e-01,  1.2390e-01, -2.1399e-01, -1.2375e+00,\n",
      "        -2.7906e-02, -1.3469e-01,  1.6912e+00,  8.2631e-01, -1.0047e+00,\n",
      "        -1.9781e+00, -2.8248e-01,  3.5653e+00, -2.6895e+00,  1.0032e+00,\n",
      "         4.6132e+00,  2.2059e+00,  2.0210e-01,  7.9893e+00,  7.3599e-01,\n",
      "         5.3831e-02, -1.3732e+00,  2.9539e+00, -1.4630e+00, -2.4408e-01,\n",
      "        -2.3353e+00, -8.2497e-02,  6.6928e-01,  4.6013e-01,  1.3650e+00,\n",
      "        -1.6948e-01,  1.2174e-01, -7.8062e-01, -9.3672e-01, -4.3733e-01,\n",
      "        -3.9437e-01,  1.8083e+00,  1.4976e-01, -2.4208e-01,  1.3716e+00,\n",
      "        -1.3881e+00, -5.7638e-01, -1.0700e-01, -1.0698e-01, -3.2254e-02,\n",
      "         1.0592e+00,  3.8542e-01, -1.7244e+00, -2.6449e-01, -3.4892e-01,\n",
      "        -1.2904e+00, -3.0843e-01,  2.7693e+00, -6.8730e-01,  1.0648e-01,\n",
      "         5.7972e-02, -6.0256e-02,  5.1993e-01,  7.6682e-01, -5.2430e-01,\n",
      "        -1.5717e+00,  5.4766e+00,  1.6315e+00, -1.9768e-01,  1.3063e+00,\n",
      "        -2.6483e-01,  1.3960e+00, -2.5335e+00, -1.7577e+00, -4.4693e+00,\n",
      "        -4.9852e+00,  2.8117e+00,  1.1467e+00, -5.5085e-02, -3.5348e-01,\n",
      "         1.3109e+00, -2.3422e-01,  8.0405e-01, -1.0623e+00,  7.4802e-02,\n",
      "        -8.5284e-01, -5.7695e-01,  2.4488e-02,  2.3749e-01,  1.8529e-02,\n",
      "         2.0815e-01,  1.1722e+00, -1.9483e-02, -3.1149e-01,  2.6484e-01,\n",
      "        -9.9409e-02,  3.6035e-01,  5.5308e-02,  1.6965e+00, -1.0895e-01,\n",
      "        -8.7050e-01,  2.1750e+00, -5.9527e-01, -5.1716e+00,  2.9141e+00,\n",
      "        -4.4355e-01, -2.2214e+00,  1.3596e-01, -2.6804e+00, -1.8029e+00,\n",
      "        -5.1038e-01,  2.0352e-01,  4.8572e-02,  1.3853e+00,  2.4064e+00,\n",
      "        -3.1075e-01,  1.2224e+00,  1.8990e+00,  4.6358e-01,  2.9658e-01,\n",
      "        -7.0571e-01, -5.2575e-01, -4.2246e-01, -7.0770e-01, -1.9649e+00,\n",
      "         4.7375e-02,  1.6250e-01,  7.9151e-02,  2.9718e-01, -3.5544e-02,\n",
      "         3.0889e+00, -4.3523e-01,  6.6593e-01,  9.5608e-02, -2.2794e-01,\n",
      "        -1.0365e+00, -1.4432e-01, -8.9278e-01, -2.6310e-01,  3.0581e-01,\n",
      "         3.0848e-01,  1.7714e+00, -3.0703e-01, -6.2831e-02, -2.7656e-02,\n",
      "         3.6868e-01, -9.3436e-01,  2.8828e-01,  3.1023e-01, -4.4669e-03,\n",
      "        -2.6278e-01,  5.1237e-01, -1.4223e-01, -3.1059e-01, -4.6375e-01,\n",
      "        -5.6476e-01, -1.5168e+00, -1.7938e+00,  5.2683e-01, -5.3024e-02,\n",
      "         7.4997e-01, -1.4782e-01, -4.2612e-01, -3.0905e-02,  1.0210e-01,\n",
      "        -8.5304e-01,  9.1954e-01,  1.1658e+00, -2.7982e-01, -6.2209e-02,\n",
      "        -1.3047e+00, -8.3143e-01,  2.1095e-01,  1.8067e-01,  2.5068e+00,\n",
      "         3.3847e+00,  1.4369e+00, -1.7996e+00, -2.6822e+00,  9.6047e-01,\n",
      "         1.5367e+00, -1.5339e+00, -1.6139e+00,  2.7389e+00, -4.8724e-01,\n",
      "        -2.5549e+00,  3.1260e+00,  2.1777e+00, -1.8561e+00,  5.7536e-01,\n",
      "        -2.6175e+00, -1.2979e+00,  1.1406e+00, -3.7542e-01,  1.3519e+00,\n",
      "        -4.7532e-01, -5.2605e-01,  7.2019e-01,  3.7362e-01,  2.3039e+00,\n",
      "        -4.1334e+00, -8.7518e-01,  4.8854e+00, -5.4637e+00,  1.0068e-01,\n",
      "        -6.0250e-01,  3.1555e+00, -3.6846e+00,  1.0493e+00,  1.1477e+00,\n",
      "         1.1501e+00, -2.4642e+00,  2.7680e-03,  3.8959e-01, -6.9177e-01,\n",
      "        -1.4256e+00, -8.9863e-01,  2.9433e+00,  1.4551e+00, -1.4629e+00,\n",
      "         1.3626e-01, -2.5412e-02,  1.2129e-01, -1.2622e+00,  7.9685e-01,\n",
      "        -1.5464e+00,  7.9934e-01,  1.9846e-02, -4.8712e-01,  1.5323e-01,\n",
      "        -3.2926e-02,  2.5632e-01, -3.5304e-01,  1.4142e+00, -1.1999e+00,\n",
      "        -2.5525e+00, -1.9270e-03,  1.0162e-01, -2.6926e-01, -8.5792e-01,\n",
      "        -7.6924e-01,  9.4565e-02,  1.0177e-01,  1.4099e-01,  4.6519e-02,\n",
      "        -4.2350e-01, -2.6944e-01,  1.3037e-01,  2.2735e+00, -1.4882e-01,\n",
      "        -3.7349e-01, -2.8402e-02, -4.7629e-03,  1.2012e-02, -9.8539e-01,\n",
      "         3.7027e+00, -1.5029e+00, -3.1558e+00,  9.1248e-01,  2.0914e-01,\n",
      "         4.4790e-01, -1.3952e+00, -1.4974e+00, -3.2481e-01,  4.6982e-01,\n",
      "        -4.1170e-02,  2.3170e+00, -2.3615e+00,  7.9415e-03,  1.7217e-02,\n",
      "         2.4509e+00,  2.1716e+00,  2.0453e-02,  1.8317e+00, -2.6878e+00,\n",
      "        -7.4387e+00,  4.4461e+00, -2.9126e+00, -8.1461e+00, -1.9895e+00,\n",
      "        -6.5697e+00, -2.8296e+00,  5.0604e-01, -3.5540e-01, -7.2408e-01,\n",
      "        -3.3789e+00,  1.5484e+00, -9.5245e-02,  2.9642e+00, -1.9676e-01,\n",
      "         2.3594e-01, -2.7076e-03,  8.8835e-01, -2.8238e-01,  1.4484e+00,\n",
      "         8.6998e-01, -7.4172e-01,  1.2332e-01, -6.2733e-02,  4.1108e-01,\n",
      "         1.1000e+00,  1.7181e+00,  3.4376e-01, -1.6018e-01, -6.8691e-02,\n",
      "        -1.4241e-01,  3.7443e-01,  4.6722e-03, -4.7240e-02,  6.1772e-02,\n",
      "         1.0696e+00,  1.2319e+00,  1.2814e-01, -2.4411e+00, -1.6328e+00,\n",
      "        -7.3974e-01,  6.9325e-01,  8.8506e-02,  6.2348e-01,  6.0304e-01,\n",
      "        -3.6534e+00, -7.7324e+00, -5.7463e+00, -6.2047e+00,  1.0499e+00,\n",
      "         3.2414e+00, -2.1091e+00, -2.5272e-01, -2.3311e-01, -7.5925e-01,\n",
      "        -2.1759e-01,  7.2883e-02,  2.5272e+00, -1.7673e+00,  3.0535e-01,\n",
      "        -1.2747e-01,  8.2923e-01, -2.2958e-01, -6.3159e-01,  4.0933e+00,\n",
      "         8.0817e-01,  7.2781e-01, -3.9104e-02, -1.3963e-02,  2.6799e+00,\n",
      "         1.9201e+00, -1.0039e+00, -1.2215e+00,  1.0496e+00, -2.0527e-01,\n",
      "        -1.2014e+00, -1.3009e+00, -5.5063e-02, -5.0052e-02, -5.3247e-01,\n",
      "         6.2507e-01, -1.4089e-01, -6.3838e-01, -8.5961e-01,  7.5648e-01,\n",
      "         2.2636e+00,  1.0459e+00, -2.0774e+00, -2.2925e+00, -9.2357e-01,\n",
      "        -1.7163e+00,  5.7084e-01,  5.8326e-01, -9.6632e-01, -9.7851e-01,\n",
      "        -1.1146e+00, -7.7807e-01, -1.0882e+00,  7.7017e-01, -4.3418e+00,\n",
      "         8.7112e-01, -4.2178e-02,  1.9500e-02, -1.3942e-01,  1.0225e+00,\n",
      "         1.3210e+00, -1.5451e+00,  6.7404e-03,  1.6023e-01, -5.2161e+00,\n",
      "         4.1142e+00,  9.4819e-01,  5.4543e-01, -1.0175e-01,  2.0335e+00,\n",
      "         7.0117e-01,  4.3908e-01,  3.8905e-01, -1.4025e-01,  1.2526e-01,\n",
      "         3.8883e-03,  7.9467e-01,  2.3741e+00,  6.1044e-01, -9.9994e-01,\n",
      "        -1.7151e+00,  2.2140e+00, -1.7501e-01, -1.1320e-01,  9.9510e-01,\n",
      "         1.1290e+00,  1.4902e+00, -4.7871e+00, -4.1088e+00,  2.5451e+00])\n"
     ]
    }
   ],
   "source": [
    "print(f'a1 = {a1.grad/((M+N)/np.sqrt(M*N))}, a2 = {a2.grad/np.sqrt(M*N)}, a3 = {a3.grad}, a4 = {a4.grad*1.4/(N-1)}, w1 = {w1.grad/N*np.sqrt(M)/10}, w2 = {w2.grad/N*np.sqrt(M)/5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2444])"
      ]
     },
     "execution_count": 1609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.grad/(2*np.sqrt(M/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4592])"
      ]
     },
     "execution_count": 1610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.grad/np.sqrt(M*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4465])"
      ]
     },
     "execution_count": 1611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4.grad*np.sqrt(2)/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5484)"
      ]
     },
     "execution_count": 1633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad.abs().mean()/N*np.sqrt(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8511)"
      ]
     },
     "execution_count": 1632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.grad.abs().median()/N*np.sqrt(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3183098861837907"
      ]
     },
     "execution_count": 1146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*2/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1705.6671)"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.grad.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1115,  0.2275, -0.4555,  0.3689,  0.6550,  0.5515,  0.3438, -0.6631,\n",
       "         0.8158, -0.1205,  0.2374, -0.3639, -0.8425, -0.6010, -0.5199,  0.0020,\n",
       "         0.5588, -0.0182, -0.2570,  0.3402, -0.1640,  0.4977, -0.3149,  0.0290,\n",
       "        -0.2168, -0.0064,  0.1437,  0.1634, -0.2613, -0.3131, -0.2773,  0.1989,\n",
       "         0.3823,  0.3129, -0.6933, -0.0030, -0.3549,  0.6032,  0.6331, -0.1449,\n",
       "         0.1356,  0.1581, -0.4372, -0.0487,  0.0219,  0.1967, -0.3185, -0.0303,\n",
       "         0.8918, -0.0673], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find numerical relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 100\n",
    "gradient = torch.zeros(nn,6, device = dev)\n",
    "\n",
    "for i in range(nn):\n",
    "    a1,a2,a3,a4,w1,w2 = random_init(M,dev)\n",
    "    X,y = forward_pass_dif(x,a1,a2,a3,a4,w1,w2,dev)\n",
    "    ls = loss(x,y)\n",
    "    ls.backward()\n",
    "    gradient[i,0] = a1.grad.abs().item()\n",
    "    gradient[i,1] = a2.grad.abs().item()\n",
    "    gradient[i,2] = a3.grad.abs().item()\n",
    "    gradient[i,3] = a4.grad.abs().item()\n",
    "    gradient[i,4] = w1.grad.abs().median()\n",
    "    gradient[i,5] = w2.grad.abs().median()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = torch.div(gradient,gradient[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([0.0052, 1.0000, 0.0017, 1.0102, 0.4305, 0.3658]),\n",
       "indices=tensor([ 9, 49, 61, 64, 72, 44]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio.median(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([8.8082e-04, 1.0000e+00, 9.8251e-04, 9.0350e-01, 5.0594e-01, 4.0735e-01]),\n",
       "indices=tensor([44, 49, 82, 52, 83, 21]))"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.median(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635.9831525952138"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a4.grad/a3.grad = (N-1)*(2/pi)\n",
    "(N-1)*2/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(380492.9688)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_a3 = torch.div(gradient[:,3],gradient[:,2])\n",
    "a4_a3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.7600)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_a3.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11362.4600)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_a3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(932.8977)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_a3.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(571.3546)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_a3 = torch.div(gradient[:,3].mean(),gradient[:,2].mean())\n",
    "a4_a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to balance the gradients for all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward pass:\n",
    "\n",
    "1. transformation phase\n",
    "\n",
    "$$\n",
    "X_k = \\frac{1}{\\sqrt{N}} \\left( a_1 x_0 + a_2 \\sum_{n=1}^{N-1} \\cos(w_k\\cdot n)x_n \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_0 \\\\ X_1 \\\\ \\vdots \\\\ X_{M-1}\n",
    "\\end{bmatrix}_{M \\times 1}\n",
    "= \n",
    "\\frac{1}{\\sqrt{N}}\n",
    "\\begin{bmatrix}\n",
    "a_{1} & a_{2}\\cos(w_0\\cdot 1) & \\cdots & a_{2}\\cos(w_0\\cdot(N-1)) \\\\ \n",
    "a_{1} & a_{2}\\cos(w_1\\cdot 1) & \\cdots & a_{2}\\cos(w_1\\cdot(N-1)) \\\\ \n",
    "\\vdots & \\vdots &  & \\vdots \\\\ \n",
    "a_{1} & a_{2}\\cos(w_{M-1}\\cdot 1) & \\cdots & a_{2}\\cos(w_{M-1}\\cdot(N-1))\n",
    "\\end{bmatrix}_{M \\times N}\n",
    "\\begin{bmatrix}\n",
    "x_{0} \\\\ x_1 \\\\ \\vdots \\\\ x_{N-1}\n",
    "\\end{bmatrix}_{N \\times 1}\n",
    "$$\n",
    "\n",
    "2. reconstruction phase\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y_0 = \\frac{a_3}{\\sqrt{M}} \\sum_{k=0}^{M-1} X_k&\\\\\n",
    "y_n = \\frac{a_4}{\\sqrt{M}} \\sum_{k=0}^{M-1}  \\cos(\\tilde{w}_k\\cdot n)X_k & n = 1,\\dots,N-1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_{N-1}\n",
    "\\end{bmatrix}_{N \\times 1}\n",
    "= \n",
    "\\frac{1}{\\sqrt{M}}\n",
    "\\begin{bmatrix}\n",
    "a_{3} & a_{3} & \\cdots & a_{3} \\\\ \n",
    "a_{4}\\cos(\\tilde{w}_0\\cdot 1) & a_{4}\\cos(\\tilde{w}_1\\cdot 1) & \\cdots & a_{4}\\cos(\\tilde{w}_{M-1}\\cdot 1) \\\\ \n",
    "\\vdots & \\vdots &  & \\vdots \\\\ \n",
    "a_{4}\\cos(\\tilde{w}_0\\cdot(N-1)) & a_{4}\\cos(\\tilde{w}_1\\cdot(N-1)) & \\cdots & a_{4}\\cos(\\tilde{w}_{M-1}\\cdot(N-1))\n",
    "\\end{bmatrix}_{N \\times M}\n",
    "\\begin{bmatrix}\n",
    "X_{0} \\\\ X_1 \\\\ \\vdots \\\\ X_{M-1}\n",
    "\\end{bmatrix}_{M \\times 1}\n",
    "$$\n",
    "\n",
    "#### Loss\n",
    "\n",
    "$$\n",
    "l = ||\\mathrm{y-x}||_{L_2}^2\n",
    "$$\n",
    "\n",
    "#### Backward pass\n",
    "$$ \n",
    "\\frac{\\partial l}{\\partial \\mathrm{y}} = 2(\\mathrm{y-x})\n",
    "$$\n",
    "\n",
    "$a_3$ is shared via $M$ connections,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_0}{\\partial a_3} = \\frac{1}{\\sqrt{M}} \\sum_{k=0}^{M-1} X_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.detach()\n",
    "x = x.detach()\n",
    "X = X.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(351.6760)"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ((y-x)**2).sum()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(351.6760, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1805)"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dy = 2 * (y-x)\n",
    "dl_dy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6418)"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2100)"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy0_da3 = X.sum()/np.sqrt(M)\n",
    "dy0_da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0379)"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_da3 = dl_dy[0] * dy0_da3\n",
    "dl_da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0379])"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03791802003979683"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.grad.abs().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial y_n}{\\partial a_4} = \\frac{1}{\\sqrt{M}} \\sum_{k=0}^{M-1}  \\cos(\\tilde{w}_k\\cdot n)X_k , \\ n = 1,\\dots,N-1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial a_4} \\\\ \\frac{\\partial y_2}{\\partial a_4} \\\\ \\vdots \\\\ \\frac{\\partial y_{N-1}}{\\partial a_4}\n",
    "\\end{bmatrix}_{(N-1) \\times 1}\n",
    "= \n",
    "\\frac{1}{\\sqrt{M}}\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\tilde{w}_0\\cdot 1) & \\cos(\\tilde{w}_1\\cdot 1) & \\cdots & \\cos(\\tilde{w}_{M-1}\\cdot 1) \\\\ \n",
    "\\cos(\\tilde{w}_0\\cdot 2) & \\cos(\\tilde{w}_1\\cdot 2) & \\cdots & \\cos(\\tilde{w}_{M-1}\\cdot 2) \\\\ \n",
    "\\vdots & \\vdots &  & \\vdots \\\\ \n",
    "\\cos(\\tilde{w}_0\\cdot(N-1)) & \\cos(\\tilde{w}_1\\cdot(N-1)) & \\cdots & \\cos(\\tilde{w}_{M-1}\\cdot(N-1))\n",
    "\\end{bmatrix}_{(N-1) \\times M}\n",
    "\\begin{bmatrix}\n",
    "X_{0} \\\\ X_1 \\\\ \\vdots \\\\ X_{M-1}\n",
    "\\end{bmatrix}_{M \\times 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial l}{\\partial a_4} = \\sum_{n=1}^{N-1}\\frac{\\partial l}{\\partial y_n}\\cdot\\frac{\\partial y_n}{\\partial a_4} = \n",
    "2[y_1 - x_1, y_2 - x_2, \\dots, y_{N-1} - x_{N-1}]\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial a_4} \\\\ \\frac{\\partial y_2}{\\partial a_4} \\\\ \\vdots \\\\ \\frac{\\partial y_{N-1}}{\\partial a_4}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_matrix = torch.cos(torch.outer(torch.arange(1,N),w2))\n",
    "dy_da4 = torch.matmul(cos_matrix,X)/np.sqrt(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2745, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_da4.abs().mean()*np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2100)"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy0_da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(75.3291, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_da4 = (dl_dy[1:]*dy_da4).sum()\n",
    "dl_da4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75.3291])"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By summing $N-1$ terms up, the gradient of $a_4$ scales up comparing to the gradient of $a_3$, since $a_3$ is shared via $M$ connections, while $a_4$ is shared via $M \\times (N-1)$ connections.\n",
    "\n",
    "However, the sum over $k$ for $a_4$ is scaled by cosine terms, which brings $X$ to \\{$\\frac{\\partial y_n}{\\partial a_4}\\}_{n = 1,\\dots,N-1}$, which forms a distribution over the range of $(-|\\frac{\\partial y_0}{\\partial a_3}|,|\\frac{\\partial y_0}{\\partial a_3}|)$. This can be seen by comparing\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_0}{\\partial a_3} = \\frac{1}{\\sqrt{M}} \\sum_{k=0}^{M-1} X_k\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_n}{\\partial a_4} = \\frac{1}{\\sqrt{M}} \\sum_{k=0}^{M-1}  \\cos(\\tilde{w}_k\\cdot n)X_k , \\ n = 1,\\dots,N-1\n",
    "$$\n",
    "\n",
    "Therefore, we need to consider the effect of cosine terms and scale $\\frac{\\partial l}{\\partial a_4}/(N-1)$ up by certain amount. A reasonable factor would be the cosine absolute average,\n",
    "$$\n",
    "\\frac{1}{\\pi} \\int_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2} \\cos(x) dx = \\frac{2}{\\pi}\n",
    "$$\n",
    "\n",
    "Therefore, we multiply $\\frac{\\partial l}{\\partial a_4}$ by $\\frac{\\pi}{2(N-1)}$ to balance its gradient with $a_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015723686954903868"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/2/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1184, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_da4*np.pi/2/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1066, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_da4*np.sqrt(2)/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0379)"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_da3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial y_n}{\\partial \\tilde{w}_k} = -\\frac{a_4}{\\sqrt{M}} \\cdot n\\sin(\\tilde{w}_k\\cdot n)X_k , \\ n = 1,\\dots,N-1\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5707963267948966"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2203)"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1851)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.845898602839955"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(np.sqrt(2)/np.pi*0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011741682974559686"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*M/N/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'abs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1362-d296978b6a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'abs'"
     ]
    }
   ],
   "source": [
    "w1.grad.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6757)"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad.abs().max() * M/N/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1144e-05)"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad.abs().min() * M/N/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0416)"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad.abs().median() * M/N/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0052])"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.grad /np.sqrt(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0379])"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approxiamation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "M = 800\n",
    "dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,a2,a3,a4,w1,w2 = random_init(M,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(N,800)*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = forward_pass_dif(x,a1,a2,a3,a4,w1,w2,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4598, -0.3606,  0.6415,  ...,  0.4045, -0.3895, -0.6628],\n",
       "        [-0.4721,  0.1397, -0.8591,  ...,  0.1167,  0.2939, -0.5597],\n",
       "        [-0.3645,  0.4974, -0.5694,  ..., -0.3329,  0.5015, -0.5941],\n",
       "        ...,\n",
       "        [ 0.7418, -0.4864,  0.0994,  ..., -0.1749,  0.7142,  0.3974],\n",
       "        [ 0.8384, -0.5902,  0.1772,  ..., -0.3368,  0.7546,  0.6148],\n",
       "        [-0.0180, -0.1045,  0.5986,  ..., -0.2249,  0.0555,  0.3196]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1465, -0.0086,  0.6379,  ..., -0.6438, -0.2735, -0.5575],\n",
       "        [ 0.9485, -0.2307, -0.6410,  ...,  0.4648,  0.8622,  0.7022],\n",
       "        [ 0.4927,  0.9810, -0.4208,  ..., -0.7656, -0.2328, -0.9784],\n",
       "        ...,\n",
       "        [ 0.1194,  0.5219,  0.5036,  ...,  0.5356, -0.6212, -0.0105],\n",
       "        [-0.3770,  0.8338, -0.4038,  ..., -0.4052,  0.4597,  0.0815],\n",
       "        [-0.4295, -0.7324,  0.9020,  ..., -0.8081,  0.6354, -0.5520]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1546, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1992, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1686, grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 1072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4739, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2155, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1807, grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:].abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9931, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2051, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1721, grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0].abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.282842712474619"
      ]
     },
     "execution_count": 1081,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1328)"
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(torch.arange(0,N).view(1,-1).type(torch.float32),x).sum(0).abs()/62500).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62500.0"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(N*(N-2)/4+N/2)/2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-54.4821)"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 3/N*2*np.pi\n",
    "w = 0.01\n",
    "torch.cos(w*torch.arange(1,N)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-346.7193)"
      ]
     },
     "execution_count": 1246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inner(torch.sin(w*torch.arange(1,N)),1.0*torch.arange(1,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0214e+02, 2.2016e+01, 7.6059e+00, 3.6358e+00, 2.0019e+00, 1.1749e+00,\n",
       "        6.9928e-01, 4.0081e-01, 2.0140e-01, 6.1494e-02, 4.0325e-02, 1.1676e-01,\n",
       "        1.7559e-01, 2.2184e-01, 2.5890e-01, 2.8898e-01, 3.1375e-01, 3.3441e-01,\n",
       "        3.5180e-01, 3.6659e-01, 3.7924e-01, 3.9022e-01, 3.9972e-01, 4.0808e-01,\n",
       "        4.1542e-01, 4.2190e-01, 4.2768e-01, 4.3281e-01, 4.3744e-01, 4.4158e-01,\n",
       "        4.4536e-01, 4.4874e-01, 4.5189e-01, 4.5464e-01, 4.5727e-01, 4.5959e-01,\n",
       "        4.6181e-01, 4.6378e-01, 4.6565e-01, 4.6731e-01, 4.6894e-01, 4.7038e-01,\n",
       "        4.7177e-01, 4.7305e-01, 4.7433e-01, 4.7534e-01, 4.7633e-01, 4.7739e-01,\n",
       "        4.7827e-01, 4.7914e-01, 4.7990e-01, 4.8072e-01, 4.8148e-01, 4.8208e-01,\n",
       "        4.8276e-01, 4.8339e-01, 4.8399e-01, 4.8468e-01, 4.8501e-01, 4.8550e-01,\n",
       "        4.8601e-01, 4.8638e-01, 4.8688e-01, 4.8723e-01, 4.8767e-01, 4.8801e-01,\n",
       "        4.8829e-01, 4.8867e-01, 4.8901e-01, 4.8934e-01, 4.8961e-01, 4.8989e-01,\n",
       "        4.9018e-01, 4.9044e-01, 4.9068e-01, 4.9094e-01, 4.9117e-01, 4.9138e-01,\n",
       "        4.9158e-01, 4.9181e-01, 4.9199e-01, 4.9221e-01, 4.9235e-01, 4.9254e-01,\n",
       "        4.9272e-01, 4.9284e-01, 4.9303e-01, 4.9321e-01, 4.9329e-01, 4.9341e-01,\n",
       "        4.9366e-01, 4.9377e-01, 4.9391e-01, 4.9402e-01, 4.9415e-01, 4.9427e-01,\n",
       "        4.9438e-01, 4.9450e-01, 4.9458e-01, 4.9468e-01, 4.9480e-01, 4.9492e-01,\n",
       "        4.9503e-01, 4.9509e-01, 4.9518e-01, 4.9531e-01, 4.9536e-01, 4.9554e-01,\n",
       "        4.9552e-01, 4.9562e-01, 4.9561e-01, 4.9568e-01, 4.9583e-01, 4.9588e-01,\n",
       "        4.9579e-01, 4.9599e-01, 4.9594e-01, 4.9613e-01, 4.9625e-01, 4.9626e-01,\n",
       "        4.9635e-01, 4.9641e-01, 4.9646e-01, 4.9649e-01, 4.9667e-01, 4.9677e-01,\n",
       "        4.9667e-01, 4.9671e-01, 4.9676e-01, 4.9679e-01, 4.9683e-01, 4.9686e-01,\n",
       "        4.9696e-01, 4.9699e-01, 4.9714e-01, 4.9702e-01, 4.9708e-01, 4.9711e-01,\n",
       "        4.9719e-01, 4.9721e-01, 4.9730e-01, 4.9711e-01, 4.9730e-01, 4.9746e-01,\n",
       "        4.9743e-01, 4.9739e-01, 4.9746e-01, 4.9747e-01, 4.9756e-01, 4.9769e-01,\n",
       "        4.9766e-01, 4.9756e-01, 4.9760e-01, 4.9764e-01, 4.9765e-01, 4.9771e-01,\n",
       "        4.9777e-01, 4.9772e-01, 4.9815e-01, 4.9778e-01, 4.9778e-01, 4.9780e-01,\n",
       "        4.9793e-01, 4.9792e-01, 4.9793e-01, 4.9801e-01, 4.9798e-01, 4.9784e-01,\n",
       "        4.9800e-01, 4.9804e-01, 4.9811e-01, 4.9796e-01, 4.9812e-01, 4.9807e-01,\n",
       "        4.9814e-01, 4.9822e-01, 4.9820e-01, 4.9822e-01, 4.9823e-01, 4.9835e-01,\n",
       "        4.9827e-01, 4.9824e-01, 4.9820e-01, 4.9824e-01, 4.9843e-01, 4.9829e-01,\n",
       "        4.9834e-01, 4.9833e-01, 4.9842e-01, 4.9830e-01, 4.9845e-01, 4.9840e-01,\n",
       "        4.9847e-01, 4.9865e-01, 4.9847e-01, 4.9844e-01, 4.9862e-01, 4.9845e-01,\n",
       "        4.9846e-01, 4.9869e-01, 4.9859e-01, 4.9859e-01, 4.9869e-01, 4.9863e-01,\n",
       "        4.9852e-01, 4.9881e-01, 4.9867e-01, 4.9869e-01, 4.9868e-01, 4.9861e-01,\n",
       "        4.9858e-01, 4.9846e-01, 4.9870e-01, 4.9868e-01, 4.9873e-01, 4.9876e-01,\n",
       "        4.9872e-01, 4.9870e-01, 4.9868e-01, 4.9884e-01, 4.9878e-01, 4.9896e-01,\n",
       "        4.9883e-01, 4.9884e-01, 4.9887e-01, 4.9908e-01, 4.9875e-01, 4.9885e-01,\n",
       "        4.9879e-01, 4.9886e-01, 4.9883e-01, 4.9878e-01, 4.9874e-01, 4.9886e-01,\n",
       "        4.9886e-01, 4.9868e-01, 4.9886e-01, 4.9885e-01, 4.9896e-01, 4.9889e-01,\n",
       "        4.9894e-01, 4.9891e-01, 4.9892e-01, 4.9882e-01, 4.9892e-01, 4.9899e-01,\n",
       "        4.9885e-01, 4.9896e-01, 4.9896e-01, 4.9902e-01, 4.9896e-01, 4.9892e-01,\n",
       "        4.9907e-01, 4.9915e-01, 4.9899e-01, 4.9903e-01, 4.9906e-01, 4.9908e-01,\n",
       "        4.9897e-01, 4.9908e-01, 4.9903e-01, 4.9907e-01, 4.9905e-01, 4.9908e-01,\n",
       "        4.9908e-01, 4.9905e-01, 4.9907e-01, 4.9909e-01, 4.9913e-01, 4.9906e-01,\n",
       "        4.9996e-01, 4.9905e-01, 4.9927e-01, 4.9895e-01, 4.9910e-01, 4.9919e-01,\n",
       "        4.9911e-01, 4.9909e-01, 4.9915e-01, 4.9903e-01, 4.9916e-01, 4.9938e-01,\n",
       "        4.9925e-01, 4.9915e-01, 4.9916e-01, 4.9918e-01, 4.9918e-01, 4.9907e-01,\n",
       "        4.9920e-01, 4.9920e-01, 4.9920e-01, 4.9914e-01, 4.9918e-01, 4.9907e-01,\n",
       "        4.9914e-01, 4.9917e-01, 4.9930e-01, 4.9918e-01, 4.9939e-01, 4.9919e-01,\n",
       "        4.9915e-01, 4.9927e-01, 4.9916e-01, 4.9926e-01, 4.9912e-01, 5.0071e-01,\n",
       "        4.9931e-01, 4.9927e-01, 4.9932e-01, 4.9927e-01, 4.9921e-01, 4.9926e-01,\n",
       "        4.9926e-01, 4.9925e-01, 4.9929e-01, 4.9932e-01, 4.9815e-01, 4.9928e-01,\n",
       "        4.9931e-01, 4.9921e-01, 4.9927e-01, 4.9929e-01, 4.9941e-01, 4.9920e-01,\n",
       "        4.9934e-01, 4.9920e-01, 4.9932e-01, 4.9934e-01, 4.9939e-01, 4.9935e-01,\n",
       "        4.9928e-01, 4.9938e-01, 4.9923e-01, 4.9927e-01, 4.9868e-01, 4.9923e-01,\n",
       "        4.9932e-01, 4.9922e-01, 4.9959e-01, 4.9928e-01, 4.9965e-01, 4.9906e-01,\n",
       "        4.9906e-01, 4.9904e-01, 4.9913e-01, 4.9929e-01, 4.9937e-01, 4.9932e-01,\n",
       "        4.9923e-01, 4.9922e-01, 4.9961e-01, 4.9992e-01, 4.9904e-01, 4.9937e-01,\n",
       "        4.9947e-01, 4.9936e-01, 4.9941e-01, 4.9942e-01, 4.9985e-01, 4.9942e-01,\n",
       "        4.9946e-01, 4.9933e-01, 4.9950e-01, 4.9946e-01, 4.9938e-01, 4.9947e-01,\n",
       "        4.9952e-01, 4.9989e-01, 4.9906e-01, 4.9945e-01, 4.9949e-01, 4.9939e-01,\n",
       "        4.9940e-01, 4.9956e-01, 4.9930e-01, 4.9955e-01, 4.9911e-01, 4.9898e-01,\n",
       "        4.9955e-01, 4.9927e-01, 4.9933e-01, 4.9938e-01, 4.9937e-01, 4.9936e-01,\n",
       "        4.9942e-01, 4.9931e-01, 4.9917e-01, 4.9937e-01, 4.9921e-01, 4.9957e-01,\n",
       "        4.9933e-01, 4.9955e-01, 4.9966e-01, 4.9951e-01, 4.9957e-01, 4.9949e-01,\n",
       "        4.9967e-01, 4.9946e-01, 4.9978e-01, 4.9944e-01, 4.9940e-01, 4.9940e-01,\n",
       "        4.9956e-01, 4.9957e-01, 4.9945e-01, 4.9971e-01, 4.9928e-01, 4.9963e-01,\n",
       "        4.9943e-01, 4.9947e-01, 4.9979e-01, 4.9947e-01, 4.9938e-01, 4.9945e-01,\n",
       "        4.9967e-01, 4.9925e-01, 4.9946e-01, 4.9947e-01, 4.9948e-01, 4.9953e-01,\n",
       "        4.9987e-01, 4.9938e-01, 4.9994e-01, 4.9951e-01, 4.9967e-01, 4.9938e-01,\n",
       "        4.9951e-01, 4.9936e-01, 4.9956e-01, 4.9959e-01, 4.9953e-01, 4.9955e-01,\n",
       "        4.9999e-01, 4.9955e-01, 4.9949e-01, 4.9945e-01, 4.9915e-01, 4.9947e-01,\n",
       "        4.9944e-01, 4.9945e-01, 4.9945e-01, 4.9951e-01, 4.9942e-01, 4.9946e-01,\n",
       "        4.9987e-01, 4.9938e-01, 4.9886e-01, 4.9948e-01, 4.9944e-01, 4.9945e-01,\n",
       "        4.9964e-01, 4.9981e-01, 4.9963e-01, 4.9905e-01, 4.9950e-01, 4.9932e-01,\n",
       "        4.9955e-01, 4.9944e-01, 4.9943e-01, 4.9931e-01, 4.9962e-01, 4.9938e-01,\n",
       "        4.9974e-01, 4.9945e-01, 4.9950e-01, 4.9959e-01, 4.9958e-01, 4.9956e-01,\n",
       "        4.9960e-01, 4.9945e-01, 4.9982e-01, 4.9951e-01, 4.9943e-01, 4.9952e-01,\n",
       "        4.9938e-01, 4.9931e-01, 4.9953e-01, 4.9955e-01, 4.9956e-01, 4.9994e-01,\n",
       "        4.9948e-01, 4.9944e-01, 4.9968e-01, 4.9946e-01, 4.9952e-01, 4.9937e-01,\n",
       "        4.9955e-01, 4.9947e-01, 4.9949e-01, 4.9936e-01, 4.9973e-01, 4.9928e-01,\n",
       "        4.9952e-01, 4.9932e-01, 4.9963e-01, 4.9941e-01, 4.9955e-01, 5.0056e-01,\n",
       "        4.9959e-01, 4.9950e-01], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.sin(torch.outer(w2,torch.arange(0,N))),1.0*torch.arange(0,N)).abs()/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 1359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.sin(torch.outer(w2,torch.arange(0,N))),1.0*torch.arange(0,N)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1500\n",
    "M = 512\n",
    "dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,a2,a3,a4,w1,w2 = random_init(M,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4552,  1.4552,  1.4552,  ...,  1.4552,  1.4552,  1.4552],\n",
       "        [ 1.3083,  1.3083,  1.3082,  ..., -1.3080, -1.3081, -1.3083],\n",
       "        [ 1.3083,  1.3083,  1.3078,  ...,  1.3072,  1.3075,  1.3082],\n",
       "        ...,\n",
       "        [ 1.1120,  1.0567, -0.2917,  ..., -0.9719, -1.0894,  0.2195],\n",
       "        [ 1.1147,  1.0531, -0.3092,  ...,  0.9896,  1.0769, -0.2107],\n",
       "        [ 1.1173,  1.0495, -0.3267,  ..., -1.0070, -1.0641,  0.2012]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 1597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2_2 = a4 * torch.cos(torch.outer(torch.arange(N, device = dev),w2))\n",
    "W2_2[0] = a3\n",
    "W2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1854e+03,  1.0134e+03,  1.0742e+02,  ...,  6.9383e-01,\n",
       "          6.7053e-01,  1.3718e+00],\n",
       "        [ 1.0134e+03,  1.3735e+03,  1.1666e+02,  ...,  7.2977e-01,\n",
       "          7.0789e-01,  1.3650e+00],\n",
       "        [ 1.0742e+02,  1.1666e+02,  1.2692e+03,  ...,  1.4327e+00,\n",
       "          1.4395e+00,  1.2280e+00],\n",
       "        ...,\n",
       "        [ 6.9383e-01,  7.2980e-01,  1.4326e+00,  ...,  1.2641e+03,\n",
       "         -2.4946e+02,  3.6114e+01],\n",
       "        [ 6.7054e-01,  7.0789e-01,  1.4395e+00,  ..., -2.4946e+02,\n",
       "          1.3083e+03,  3.1293e+01],\n",
       "        [ 1.3718e+00,  1.3650e+00,  1.2280e+00,  ...,  3.6114e+01,\n",
       "          3.1293e+01,  1.3022e+03]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 1598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.transpose(W2_2,0,1),W2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([745.0869,  -6.8673, -10.8802,  ...,  29.4976,  10.6277, -25.1379],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 1599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2_2.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-268.8798, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 1600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2_2[1:,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
